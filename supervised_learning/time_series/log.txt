blackrukh@3lackrukh:~/atlas-machine_learning/supervised_learning/time_series$ ./forecast_btc.py 
2025-03-27 21:07:34.461196: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-27 21:07:34.461371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-27 21:07:34.648347: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-27 21:07:35.010483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-27 21:07:38.439482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Bitcoin Price Forecasting with RNNs
=================================

Loaded data: X shape (69289, 24, 21), y shape (69289,)
Using target column: Close_log_ret for evaluation
Train set: (49887, 24, 21), (49887,)
Validation set: (5544, 24, 21), (5544,)
Test set: (13858, 24, 21), (13858,)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 bidirectional (Bidirection  (None, 64)                13824     
 al)                                                             
                                                                 
 dense (Dense)               (None, 1)                 65        
                                                                 
=================================================================
Total params: 13889 (54.25 KB)
Trainable params: 13889 (54.25 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/50
1559/1559 [==============================] - 35s 21ms/step - loss: 0.0171 - mae: 0.0562 - val_loss: 0.0032 - val_mae: 0.0386 - lr: 0.0010
Epoch 2/50
1559/1559 [==============================] - 32s 20ms/step - loss: 0.0049 - mae: 0.0418 - val_loss: 0.0028 - val_mae: 0.0338 - lr: 0.0010
Epoch 3/50
1559/1559 [==============================] - 32s 20ms/step - loss: 0.0046 - mae: 0.0409 - val_loss: 0.0031 - val_mae: 0.0374 - lr: 0.0010
Epoch 4/50
1559/1559 [==============================] - 32s 20ms/step - loss: 0.0045 - mae: 0.0399 - val_loss: 0.0026 - val_mae: 0.0316 - lr: 0.0010
Epoch 5/50
1559/1559 [==============================] - 30s 19ms/step - loss: 0.0044 - mae: 0.0388 - val_loss: 0.0027 - val_mae: 0.0328 - lr: 0.0010
Epoch 6/50
1559/1559 [==============================] - 17s 11ms/step - loss: 0.0043 - mae: 0.0385 - val_loss: 0.0030 - val_mae: 0.0371 - lr: 0.0010
Epoch 7/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0043 - mae: 0.0379 - val_loss: 0.0032 - val_mae: 0.0393 - lr: 0.0010
Epoch 8/50
1559/1559 [==============================] - 18s 11ms/step - loss: 0.0043 - mae: 0.0381 - val_loss: 0.0036 - val_mae: 0.0446 - lr: 0.0010
Epoch 9/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0042 - mae: 0.0376 - val_loss: 0.0030 - val_mae: 0.0359 - lr: 0.0010
Epoch 10/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0042 - mae: 0.0369 - val_loss: 0.0026 - val_mae: 0.0316 - lr: 5.0000e-04
Epoch 11/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0042 - mae: 0.0368 - val_loss: 0.0028 - val_mae: 0.0339 - lr: 5.0000e-04
Epoch 12/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0042 - mae: 0.0367 - val_loss: 0.0028 - val_mae: 0.0346 - lr: 5.0000e-04
Epoch 13/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0041 - mae: 0.0369 - val_loss: 0.0026 - val_mae: 0.0304 - lr: 5.0000e-04
Epoch 14/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0041 - mae: 0.0367 - val_loss: 0.0025 - val_mae: 0.0305 - lr: 5.0000e-04
Epoch 15/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0027 - val_mae: 0.0334 - lr: 2.5000e-04
Epoch 16/50
1559/1559 [==============================] - 18s 11ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0310 - lr: 2.5000e-04
Epoch 17/50
1559/1559 [==============================] - 18s 11ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0304 - lr: 2.5000e-04
Epoch 18/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0309 - lr: 2.5000e-04
Epoch 19/50
1559/1559 [==============================] - 19s 12ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0025 - val_mae: 0.0304 - lr: 2.5000e-04
Epoch 20/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0041 - mae: 0.0362 - val_loss: 0.0025 - val_mae: 0.0303 - lr: 1.2500e-04
Epoch 21/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0041 - mae: 0.0362 - val_loss: 0.0026 - val_mae: 0.0303 - lr: 1.2500e-04
Epoch 22/50
1559/1559 [==============================] - 20s 13ms/step - loss: 0.0041 - mae: 0.0362 - val_loss: 0.0026 - val_mae: 0.0309 - lr: 1.2500e-04
Epoch 23/50
1559/1559 [==============================] - 21s 13ms/step - loss: 0.0040 - mae: 0.0362 - val_loss: 0.0027 - val_mae: 0.0327 - lr: 1.2500e-04
Epoch 24/50
1559/1559 [==============================] - 19s 12ms/step - loss: 0.0040 - mae: 0.0362 - val_loss: 0.0025 - val_mae: 0.0303 - lr: 1.2500e-04
Epoch 25/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0025 - val_mae: 0.0304 - lr: 6.2500e-05
Epoch 26/50
1559/1559 [==============================] - 18s 12ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0026 - val_mae: 0.0304 - lr: 6.2500e-05
Epoch 27/50
1559/1559 [==============================] - 19s 12ms/step - loss: 0.0040 - mae: 0.0361 - val_loss: 0.0026 - val_mae: 0.0306 - lr: 6.2500e-05
Epoch 28/50
1559/1559 [==============================] - 19s 12ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0026 - val_mae: 0.0305 - lr: 6.2500e-05
Epoch 29/50
1559/1559 [==============================] - 20s 13ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0025 - val_mae: 0.0304 - lr: 6.2500e-05
Epoch 30/50
1559/1559 [==============================] - 20s 13ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0025 - val_mae: 0.0303 - lr: 3.1250e-05
434/434 [==============================] - 2s 4ms/step
Scaled MSE (on log returns): 0.002055
Scaled RMSE (on log returns): 0.045331
Scaled MAE (on log returns): 0.024785
Starting price for conversion: $6689.04

Metrics on actual prices:
MSE: 3741.56
RMSE: 61.17
MAE: 32.06
MAPE: 0.45%
/home/blackrukh/.local/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
Bitcoin price forecasting completed!