blackrukh@3lackrukh:~/atlas-machine_learning/supervised_learning/time_series$ ./forecast_btc.py 
2025-03-25 11:38:46.919638: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-25 11:38:46.919948: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-25 11:38:47.125827: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-25 11:38:47.560373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-25 11:38:50.761661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Bitcoin Price Forecasting with RNNs
=================================

Loaded data: X shape (68412, 24, 13), y shape (68412,)
Train set: (49256, 24, 13), (49256,)
Validation set: (5473, 24, 13), (5473,)
Test set: (13683, 24, 13), (13683,)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 32)                5888      
                                                                 
 dense (Dense)               (None, 1)                 33        
                                                                 
=================================================================
Total params: 5921 (23.13 KB)
Trainable params: 5921 (23.13 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/50
 764/1540 [=============>................] - ETA: 8s - loss: 0.1466 - mae: 0.0934^Z  
[2]+  Stopped                 ./forecast_btc.py
blackrukh@3lackrukh:~/atlas-machine_learning/supervised_learning/time_series$ ./forecast_btc.py 
2025-03-25 11:40:54.092467: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-25 11:40:54.092529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-25 11:40:54.093481: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-25 11:40:54.099164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-25 11:40:54.893442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Bitcoin Price Forecasting with RNNs
=================================

Loaded data: X shape (68412, 24, 13), y shape (68412,)
Train set: (49256, 24, 13), (49256,)
Validation set: (5473, 24, 13), (5473,)
Test set: (13683, 24, 13), (13683,)
2025-03-25 11:40:56.606207: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122942976 exceeds 10% of free system memory.
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 1)                 60        
                                                                 
 dense (Dense)               (None, 1)                 2         
                                                                 
=================================================================
Total params: 62 (248.00 Byte)
Trainable params: 62 (248.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
2025-03-25 11:40:56.942419: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122942976 exceeds 10% of free system memory.
Epoch 1/50
1540/1540 [==============================] - 15s 9ms/step - loss: 0.0126 - mae: 0.0562 - val_loss: 0.0073 - val_mae: 0.0749 - lr: 0.0010
Epoch 2/50
1540/1540 [==============================] - 12s 8ms/step - loss: 0.0120 - mae: 0.0577 - val_loss: 0.0043 - val_mae: 0.0567 - lr: 0.0010
Epoch 3/50
1540/1540 [==============================] - 14s 9ms/step - loss: 0.0035 - mae: 0.0268 - val_loss: 0.0041 - val_mae: 0.0546 - lr: 0.0010
Epoch 4/50
1540/1540 [==============================] - 12s 8ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 0.0019 - val_mae: 0.0369 - lr: 0.0010
Epoch 5/50
1540/1540 [==============================] - 12s 8ms/step - loss: 7.4942e-04 - mae: 0.0155 - val_loss: 0.0011 - val_mae: 0.0282 - lr: 0.0010
Epoch 6/50
1540/1540 [==============================] - 13s 8ms/step - loss: 5.3554e-04 - mae: 0.0134 - val_loss: 2.3452e-04 - val_mae: 0.0123 - lr: 0.0010
Epoch 7/50
1540/1540 [==============================] - 14s 9ms/step - loss: 3.9209e-04 - mae: 0.0112 - val_loss: 3.0074e-04 - val_mae: 0.0143 - lr: 0.0010
Epoch 8/50
1540/1540 [==============================] - 13s 8ms/step - loss: 2.6030e-04 - mae: 0.0091 - val_loss: 1.4282e-04 - val_mae: 0.0095 - lr: 0.0010
Epoch 9/50
1540/1540 [==============================] - 14s 9ms/step - loss: 2.0070e-04 - mae: 0.0078 - val_loss: 2.6874e-04 - val_mae: 0.0141 - lr: 0.0010
Epoch 10/50
1540/1540 [==============================] - 12s 8ms/step - loss: 1.4262e-04 - mae: 0.0064 - val_loss: 1.3350e-04 - val_mae: 0.0095 - lr: 0.0010
Epoch 11/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.1985e-04 - mae: 0.0057 - val_loss: 1.6789e-04 - val_mae: 0.0110 - lr: 0.0010
Epoch 12/50
1540/1540 [==============================] - 13s 9ms/step - loss: 9.7675e-05 - mae: 0.0052 - val_loss: 1.7326e-04 - val_mae: 0.0113 - lr: 0.0010
Epoch 13/50
1540/1540 [==============================] - 14s 9ms/step - loss: 7.8248e-05 - mae: 0.0044 - val_loss: 7.4125e-05 - val_mae: 0.0065 - lr: 0.0010
Epoch 14/50
1540/1540 [==============================] - 14s 9ms/step - loss: 7.1790e-05 - mae: 0.0041 - val_loss: 5.7778e-05 - val_mae: 0.0056 - lr: 0.0010
Epoch 15/50
1540/1540 [==============================] - 13s 9ms/step - loss: 6.3805e-05 - mae: 0.0038 - val_loss: 7.6077e-05 - val_mae: 0.0069 - lr: 0.0010
Epoch 16/50
1540/1540 [==============================] - 13s 9ms/step - loss: 5.6269e-05 - mae: 0.0035 - val_loss: 5.9193e-05 - val_mae: 0.0057 - lr: 5.0000e-04
Epoch 17/50
1540/1540 [==============================] - 13s 9ms/step - loss: 5.5992e-05 - mae: 0.0035 - val_loss: 1.0900e-04 - val_mae: 0.0087 - lr: 5.0000e-04
Epoch 18/50
1540/1540 [==============================] - 14s 9ms/step - loss: 5.1319e-05 - mae: 0.0033 - val_loss: 1.0995e-04 - val_mae: 0.0088 - lr: 5.0000e-04
Epoch 19/50
1540/1540 [==============================] - 13s 8ms/step - loss: 4.9345e-05 - mae: 0.0031 - val_loss: 9.5960e-05 - val_mae: 0.0078 - lr: 5.0000e-04
Epoch 20/50
1540/1540 [==============================] - 13s 8ms/step - loss: 4.9836e-05 - mae: 0.0031 - val_loss: 6.1163e-05 - val_mae: 0.0059 - lr: 5.0000e-04
Epoch 21/50
1540/1540 [==============================] - 14s 9ms/step - loss: 4.5398e-05 - mae: 0.0030 - val_loss: 5.8179e-05 - val_mae: 0.0056 - lr: 2.5000e-04
Epoch 22/50
1540/1540 [==============================] - 12s 8ms/step - loss: 4.6351e-05 - mae: 0.0029 - val_loss: 1.3991e-04 - val_mae: 0.0102 - lr: 2.5000e-04
Epoch 23/50
1540/1540 [==============================] - 13s 8ms/step - loss: 4.6834e-05 - mae: 0.0029 - val_loss: 4.6787e-05 - val_mae: 0.0048 - lr: 2.5000e-04
Epoch 24/50
1540/1540 [==============================] - 15s 9ms/step - loss: 4.4615e-05 - mae: 0.0029 - val_loss: 5.8006e-05 - val_mae: 0.0058 - lr: 2.5000e-04
Epoch 25/50
1540/1540 [==============================] - 13s 9ms/step - loss: 4.2921e-05 - mae: 0.0028 - val_loss: 4.9290e-05 - val_mae: 0.0050 - lr: 2.5000e-04
Epoch 26/50
1540/1540 [==============================] - 12s 8ms/step - loss: 4.2050e-05 - mae: 0.0027 - val_loss: 5.4976e-05 - val_mae: 0.0053 - lr: 1.2500e-04
Epoch 27/50
1540/1540 [==============================] - 13s 8ms/step - loss: 4.1026e-05 - mae: 0.0027 - val_loss: 5.3540e-05 - val_mae: 0.0054 - lr: 1.2500e-04
Epoch 28/50
1540/1540 [==============================] - 12s 8ms/step - loss: 3.9921e-05 - mae: 0.0026 - val_loss: 5.5944e-05 - val_mae: 0.0055 - lr: 1.2500e-04
Epoch 29/50
1540/1540 [==============================] - 14s 9ms/step - loss: 4.1099e-05 - mae: 0.0027 - val_loss: 6.8050e-05 - val_mae: 0.0065 - lr: 1.2500e-04
Epoch 30/50
1540/1540 [==============================] - 12s 8ms/step - loss: 3.9420e-05 - mae: 0.0026 - val_loss: 5.1262e-05 - val_mae: 0.0052 - lr: 1.2500e-04
Epoch 31/50
1540/1540 [==============================] - 15s 9ms/step - loss: 3.9165e-05 - mae: 0.0026 - val_loss: 5.3796e-05 - val_mae: 0.0054 - lr: 6.2500e-05
Epoch 32/50
1540/1540 [==============================] - 13s 9ms/step - loss: 3.8577e-05 - mae: 0.0025 - val_loss: 4.8664e-05 - val_mae: 0.0049 - lr: 6.2500e-05
Epoch 33/50
1540/1540 [==============================] - 13s 8ms/step - loss: 3.8779e-05 - mae: 0.0025 - val_loss: 5.5186e-05 - val_mae: 0.0056 - lr: 6.2500e-05
428/428 [==============================] - 1s 3ms/step
Scaled MSE: 0.000056
Scaled RMSE: 0.007465
Scaled MAE: 0.004745
Original MSE: 18777.82
Original RMSE: 137.03
Original MAE: 87.11
/home/blackrukh/.local/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
Bitcoin price forecasting completed!