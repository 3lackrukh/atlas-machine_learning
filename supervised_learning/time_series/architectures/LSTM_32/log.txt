blackrukh@3lackrukh:~/atlas-machine_learning/supervised_learning/time_series$ ./forecast_btc.py 
2025-03-24 20:48:32.802373: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-24 20:48:32.802508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-24 20:48:32.972480: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-24 20:48:33.328126: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-24 20:48:36.912875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Bitcoin Price Forecasting with RNNs
=================================

Loaded data: X shape (68412, 24, 13), y shape (68412,)
Train set: (49256, 24, 13), (49256,)
Validation set: (5473, 24, 13), (5473,)
Test set: (13683, 24, 13), (13683,)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 32)                5888      
                                                                 
 dense (Dense)               (None, 1)                 33        
                                                                 
=================================================================
Total params: 5921 (23.13 KB)
Trainable params: 5921 (23.13 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/50
1540/1540 [==============================] - 34s 21ms/step - loss: 0.0847 - mae: 0.0641 - val_loss: 5.0556e-04 - val_mae: 0.0172 - lr: 0.0010
Epoch 2/50
1540/1540 [==============================] - 16s 10ms/step - loss: 0.0011 - mae: 0.0132 - val_loss: 7.6890e-04 - val_mae: 0.0198 - lr: 0.0010
Epoch 3/50
1540/1540 [==============================] - 16s 11ms/step - loss: 3.6898e-04 - mae: 0.0091 - val_loss: 0.0010 - val_mae: 0.0270 - lr: 0.0010
Epoch 4/50
1540/1540 [==============================] - 17s 11ms/step - loss: 2.5431e-04 - mae: 0.0082 - val_loss: 0.0017 - val_mae: 0.0380 - lr: 0.0010
Epoch 5/50
1540/1540 [==============================] - 17s 11ms/step - loss: 1.5936e-04 - mae: 0.0069 - val_loss: 0.0011 - val_mae: 0.0307 - lr: 0.0010
Epoch 6/50
1540/1540 [==============================] - 17s 11ms/step - loss: 1.7470e-04 - mae: 0.0071 - val_loss: 7.9827e-04 - val_mae: 0.0216 - lr: 0.0010
Epoch 7/50
1540/1540 [==============================] - 16s 11ms/step - loss: 7.4949e-05 - mae: 0.0041 - val_loss: 5.5372e-04 - val_mae: 0.0184 - lr: 5.0000e-04
Epoch 8/50
1540/1540 [==============================] - 16s 11ms/step - loss: 6.6280e-05 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0337 - lr: 5.0000e-04
Epoch 9/50
1540/1540 [==============================] - 16s 10ms/step - loss: 6.0466e-05 - mae: 0.0038 - val_loss: 1.9303e-04 - val_mae: 0.0088 - lr: 5.0000e-04
Epoch 10/50
1540/1540 [==============================] - 14s 9ms/step - loss: 7.0294e-05 - mae: 0.0042 - val_loss: 2.2907e-04 - val_mae: 0.0087 - lr: 5.0000e-04
Epoch 11/50
1540/1540 [==============================] - 15s 10ms/step - loss: 4.5408e-05 - mae: 0.0032 - val_loss: 4.1998e-04 - val_mae: 0.0179 - lr: 5.0000e-04
Epoch 12/50
1540/1540 [==============================] - 15s 10ms/step - loss: 3.9540e-05 - mae: 0.0031 - val_loss: 3.3575e-05 - val_mae: 0.0041 - lr: 5.0000e-04
Epoch 13/50
1540/1540 [==============================] - 15s 10ms/step - loss: 3.4931e-05 - mae: 0.0030 - val_loss: 6.5823e-05 - val_mae: 0.0067 - lr: 5.0000e-04
Epoch 14/50
1540/1540 [==============================] - 15s 10ms/step - loss: 2.9477e-05 - mae: 0.0026 - val_loss: 1.9920e-04 - val_mae: 0.0127 - lr: 5.0000e-04
Epoch 15/50
1540/1540 [==============================] - 15s 10ms/step - loss: 3.2893e-05 - mae: 0.0029 - val_loss: 1.6504e-04 - val_mae: 0.0099 - lr: 5.0000e-04
Epoch 16/50
1540/1540 [==============================] - 15s 10ms/step - loss: 3.3387e-05 - mae: 0.0027 - val_loss: 7.5219e-04 - val_mae: 0.0260 - lr: 5.0000e-04
Epoch 17/50
1540/1540 [==============================] - 14s 9ms/step - loss: 2.6496e-05 - mae: 0.0025 - val_loss: 3.1727e-05 - val_mae: 0.0043 - lr: 5.0000e-04
Epoch 18/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.6807e-05 - mae: 0.0017 - val_loss: 1.5712e-04 - val_mae: 0.0111 - lr: 2.5000e-04
Epoch 19/50
1540/1540 [==============================] - 15s 9ms/step - loss: 2.0660e-05 - mae: 0.0019 - val_loss: 3.6322e-05 - val_mae: 0.0046 - lr: 2.5000e-04
Epoch 20/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.5912e-05 - mae: 0.0017 - val_loss: 3.3066e-05 - val_mae: 0.0044 - lr: 2.5000e-04
Epoch 21/50
1540/1540 [==============================] - 15s 10ms/step - loss: 1.8552e-05 - mae: 0.0018 - val_loss: 3.3424e-05 - val_mae: 0.0044 - lr: 2.5000e-04
Epoch 22/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.5665e-05 - mae: 0.0017 - val_loss: 6.9591e-05 - val_mae: 0.0065 - lr: 2.5000e-04
Epoch 23/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.3412e-05 - mae: 0.0015 - val_loss: 5.9531e-05 - val_mae: 0.0062 - lr: 1.2500e-04
Epoch 24/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.4129e-05 - mae: 0.0015 - val_loss: 3.7108e-05 - val_mae: 0.0049 - lr: 1.2500e-04
Epoch 25/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.7812e-05 - mae: 0.0016 - val_loss: 3.0785e-05 - val_mae: 0.0042 - lr: 1.2500e-04
Epoch 26/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.1563e-05 - mae: 0.0013 - val_loss: 3.0615e-05 - val_mae: 0.0042 - lr: 1.2500e-04
Epoch 27/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.2553e-05 - mae: 0.0014 - val_loss: 2.2320e-05 - val_mae: 0.0033 - lr: 1.2500e-04
Epoch 28/50
1540/1540 [==============================] - 15s 10ms/step - loss: 1.0996e-05 - mae: 0.0012 - val_loss: 8.5087e-05 - val_mae: 0.0080 - lr: 6.2500e-05
Epoch 29/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.1393e-05 - mae: 0.0013 - val_loss: 1.8668e-05 - val_mae: 0.0029 - lr: 6.2500e-05
Epoch 30/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.1550e-05 - mae: 0.0013 - val_loss: 2.2920e-05 - val_mae: 0.0035 - lr: 6.2500e-05
Epoch 31/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.1454e-05 - mae: 0.0012 - val_loss: 1.0957e-04 - val_mae: 0.0092 - lr: 6.2500e-05
Epoch 32/50
1540/1540 [==============================] - 16s 10ms/step - loss: 1.1789e-05 - mae: 0.0012 - val_loss: 3.5023e-05 - val_mae: 0.0046 - lr: 6.2500e-05
Epoch 33/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.0745e-05 - mae: 0.0012 - val_loss: 2.5149e-05 - val_mae: 0.0036 - lr: 3.1250e-05
Epoch 34/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.0694e-05 - mae: 0.0012 - val_loss: 6.4367e-05 - val_mae: 0.0069 - lr: 3.1250e-05
Epoch 35/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.0810e-05 - mae: 0.0012 - val_loss: 2.1961e-05 - val_mae: 0.0033 - lr: 3.1250e-05
Epoch 36/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.0358e-05 - mae: 0.0012 - val_loss: 1.9138e-05 - val_mae: 0.0030 - lr: 3.1250e-05
Epoch 37/50
1540/1540 [==============================] - 14s 9ms/step - loss: 1.0262e-05 - mae: 0.0012 - val_loss: 2.3275e-05 - val_mae: 0.0036 - lr: 3.1250e-05
Epoch 38/50
1540/1540 [==============================] - 15s 9ms/step - loss: 1.0073e-05 - mae: 0.0011 - val_loss: 1.8388e-05 - val_mae: 0.0028 - lr: 1.5625e-05
Epoch 39/50
1540/1540 [==============================] - 15s 9ms/step - loss: 9.9948e-06 - mae: 0.0011 - val_loss: 2.0095e-05 - val_mae: 0.0030 - lr: 1.5625e-05
Epoch 40/50
1540/1540 [==============================] - 15s 9ms/step - loss: 9.9153e-06 - mae: 0.0011 - val_loss: 1.8254e-05 - val_mae: 0.0027 - lr: 1.5625e-05
Epoch 41/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.9469e-06 - mae: 0.0011 - val_loss: 2.6952e-05 - val_mae: 0.0039 - lr: 1.5625e-05
Epoch 42/50
1540/1540 [==============================] - 15s 10ms/step - loss: 1.0022e-05 - mae: 0.0011 - val_loss: 1.9042e-05 - val_mae: 0.0029 - lr: 1.5625e-05
Epoch 43/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.6412e-06 - mae: 0.0011 - val_loss: 1.7974e-05 - val_mae: 0.0028 - lr: 7.8125e-06
Epoch 44/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.6890e-06 - mae: 0.0011 - val_loss: 1.7790e-05 - val_mae: 0.0028 - lr: 7.8125e-06
Epoch 45/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.6071e-06 - mae: 0.0011 - val_loss: 1.9289e-05 - val_mae: 0.0030 - lr: 7.8125e-06
Epoch 46/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.5850e-06 - mae: 0.0011 - val_loss: 1.8486e-05 - val_mae: 0.0029 - lr: 7.8125e-06
Epoch 47/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.8048e-06 - mae: 0.0011 - val_loss: 2.1278e-05 - val_mae: 0.0032 - lr: 7.8125e-06
Epoch 48/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.5388e-06 - mae: 0.0011 - val_loss: 1.7246e-05 - val_mae: 0.0027 - lr: 3.9063e-06
Epoch 49/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.4490e-06 - mae: 0.0011 - val_loss: 1.8331e-05 - val_mae: 0.0029 - lr: 3.9063e-06
Epoch 50/50
1540/1540 [==============================] - 14s 9ms/step - loss: 9.4855e-06 - mae: 0.0011 - val_loss: 1.7404e-05 - val_mae: 0.0027 - lr: 3.9063e-06
428/428 [==============================] - 2s 4ms/step
Scaled MSE: 0.000016
Scaled RMSE: 0.004041
Scaled MAE: 0.002344
Original MSE: 5501.12
Original RMSE: 74.17
Original MAE: 43.03
/home/blackrukh/.local/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
Bitcoin price forecasting completed!