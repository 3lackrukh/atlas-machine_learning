./forecast_btc.py 
2025-03-25 13:49:30.217596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-25 13:49:30.217705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-25 13:49:30.219877: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-25 13:49:30.237145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-25 13:49:31.388799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Bitcoin Price Forecasting with RNNs
=================================

Loaded data: X shape (68412, 24, 13), y shape (68412,)
Train set: (49256, 24, 13), (49256,)
Validation set: (5473, 24, 13), (5473,)
Test set: (13683, 24, 13), (13683,)
2025-03-25 13:49:34.035009: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122942976 exceeds 10% of free system memory.
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 bidirectional (Bidirection  (None, 64)                11776     
 al)                                                             
                                                                 
 dense (Dense)               (None, 1)                 65        
                                                                 
=================================================================
Total params: 11841 (46.25 KB)
Trainable params: 11841 (46.25 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
2025-03-25 13:49:34.552507: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122942976 exceeds 10% of free system memory.
Epoch 1/50
1540/1540 [==============================] - 34s 21ms/step - loss: 0.0051 - mae: 0.0189 - val_loss: 3.8882e-04 - val_mae: 0.0154 - lr: 0.0010
Epoch 2/50
1540/1540 [==============================] - 16s 10ms/step - loss: 2.3985e-04 - mae: 0.0072 - val_loss: 1.7886e-04 - val_mae: 0.0099 - lr: 0.0010
Epoch 3/50
1540/1540 [==============================] - 18s 12ms/step - loss: 1.4775e-04 - mae: 0.0060 - val_loss: 6.4725e-04 - val_mae: 0.0222 - lr: 0.0010
Epoch 4/50
1540/1540 [==============================] - 19s 12ms/step - loss: 9.1263e-05 - mae: 0.0048 - val_loss: 3.1478e-04 - val_mae: 0.0150 - lr: 0.0010
Epoch 5/50
1540/1540 [==============================] - 18s 12ms/step - loss: 8.9064e-05 - mae: 0.0046 - val_loss: 3.3938e-04 - val_mae: 0.0161 - lr: 0.0010
Epoch 6/50
1540/1540 [==============================] - 19s 13ms/step - loss: 7.0630e-05 - mae: 0.0039 - val_loss: 4.1276e-04 - val_mae: 0.0179 - lr: 0.0010
Epoch 7/50
1540/1540 [==============================] - 20s 13ms/step - loss: 4.7252e-05 - mae: 0.0033 - val_loss: 2.9438e-04 - val_mae: 0.0159 - lr: 0.0010
Epoch 8/50
1540/1540 [==============================] - 20s 13ms/step - loss: 2.5993e-05 - mae: 0.0023 - val_loss: 1.9094e-04 - val_mae: 0.0119 - lr: 5.0000e-04
Epoch 9/50
1540/1540 [==============================] - 20s 13ms/step - loss: 3.0104e-05 - mae: 0.0026 - val_loss: 7.4203e-05 - val_mae: 0.0067 - lr: 5.0000e-04
Epoch 10/50
1540/1540 [==============================] - 21s 14ms/step - loss: 2.6147e-05 - mae: 0.0023 - val_loss: 1.2326e-04 - val_mae: 0.0094 - lr: 5.0000e-04
Epoch 11/50
1540/1540 [==============================] - 20s 13ms/step - loss: 2.2780e-05 - mae: 0.0022 - val_loss: 4.3995e-05 - val_mae: 0.0049 - lr: 5.0000e-04
Epoch 12/50
1540/1540 [==============================] - 20s 13ms/step - loss: 2.3846e-05 - mae: 0.0022 - val_loss: 9.5223e-05 - val_mae: 0.0078 - lr: 5.0000e-04
Epoch 13/50
1540/1540 [==============================] - 20s 13ms/step - loss: 2.5084e-05 - mae: 0.0020 - val_loss: 7.0529e-05 - val_mae: 0.0064 - lr: 5.0000e-04
Epoch 14/50
1540/1540 [==============================] - 19s 13ms/step - loss: 1.8988e-05 - mae: 0.0018 - val_loss: 1.0603e-04 - val_mae: 0.0087 - lr: 5.0000e-04
Epoch 15/50
1540/1540 [==============================] - 19s 12ms/step - loss: 1.4727e-05 - mae: 0.0015 - val_loss: 7.4563e-05 - val_mae: 0.0069 - lr: 2.5000e-04
Epoch 16/50
1540/1540 [==============================] - 19s 12ms/step - loss: 1.5284e-05 - mae: 0.0016 - val_loss: 5.2192e-05 - val_mae: 0.0057 - lr: 2.5000e-04
Epoch 17/50
1540/1540 [==============================] - 19s 13ms/step - loss: 1.5842e-05 - mae: 0.0016 - val_loss: 4.4228e-05 - val_mae: 0.0048 - lr: 2.5000e-04
Epoch 18/50
1540/1540 [==============================] - 18s 12ms/step - loss: 1.4998e-05 - mae: 0.0015 - val_loss: 3.2700e-05 - val_mae: 0.0042 - lr: 2.5000e-04
Epoch 19/50
1540/1540 [==============================] - 18s 12ms/step - loss: 1.5212e-05 - mae: 0.0015 - val_loss: 3.3854e-05 - val_mae: 0.0041 - lr: 2.5000e-04
Epoch 20/50
1540/1540 [==============================] - 18s 12ms/step - loss: 1.1564e-05 - mae: 0.0013 - val_loss: 9.4869e-05 - val_mae: 0.0080 - lr: 1.2500e-04
Epoch 21/50
1540/1540 [==============================] - 18s 11ms/step - loss: 1.1949e-05 - mae: 0.0013 - val_loss: 6.1260e-05 - val_mae: 0.0065 - lr: 1.2500e-04
Epoch 22/50
1540/1540 [==============================] - 18s 11ms/step - loss: 1.1774e-05 - mae: 0.0013 - val_loss: 3.5230e-05 - val_mae: 0.0046 - lr: 1.2500e-04
Epoch 23/50
1540/1540 [==============================] - 18s 12ms/step - loss: 1.1503e-05 - mae: 0.0013 - val_loss: 3.9736e-05 - val_mae: 0.0047 - lr: 1.2500e-04
Epoch 24/50
1540/1540 [==============================] - 18s 12ms/step - loss: 1.1246e-05 - mae: 0.0012 - val_loss: 3.0000e-05 - val_mae: 0.0040 - lr: 1.2500e-04
Epoch 25/50
1540/1540 [==============================] - 18s 12ms/step - loss: 1.0759e-05 - mae: 0.0012 - val_loss: 2.8388e-05 - val_mae: 0.0039 - lr: 6.2500e-05
Epoch 26/50
1540/1540 [==============================] - 18s 11ms/step - loss: 1.0477e-05 - mae: 0.0012 - val_loss: 2.5238e-05 - val_mae: 0.0035 - lr: 6.2500e-05
Epoch 27/50
1540/1540 [==============================] - 18s 11ms/step - loss: 1.0320e-05 - mae: 0.0012 - val_loss: 3.1560e-05 - val_mae: 0.0042 - lr: 6.2500e-05
Epoch 28/50
1540/1540 [==============================] - 18s 11ms/step - loss: 1.0738e-05 - mae: 0.0011 - val_loss: 2.2126e-05 - val_mae: 0.0031 - lr: 6.2500e-05
Epoch 29/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.9915e-06 - mae: 0.0011 - val_loss: 4.5322e-05 - val_mae: 0.0053 - lr: 6.2500e-05
Epoch 30/50
1540/1540 [==============================] - 19s 12ms/step - loss: 1.0126e-05 - mae: 0.0011 - val_loss: 2.3151e-05 - val_mae: 0.0032 - lr: 3.1250e-05
Epoch 31/50
1540/1540 [==============================] - 18s 11ms/step - loss: 1.0254e-05 - mae: 0.0011 - val_loss: 3.2362e-05 - val_mae: 0.0045 - lr: 3.1250e-05
Epoch 32/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.6810e-06 - mae: 0.0011 - val_loss: 2.8517e-05 - val_mae: 0.0038 - lr: 3.1250e-05
Epoch 33/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.7728e-06 - mae: 0.0011 - val_loss: 3.8479e-05 - val_mae: 0.0051 - lr: 3.1250e-05
Epoch 34/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.7649e-06 - mae: 0.0011 - val_loss: 2.2570e-05 - val_mae: 0.0032 - lr: 3.1250e-05
Epoch 35/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.3581e-06 - mae: 0.0010 - val_loss: 2.1031e-05 - val_mae: 0.0030 - lr: 1.5625e-05
Epoch 36/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.3427e-06 - mae: 0.0010 - val_loss: 2.2252e-05 - val_mae: 0.0031 - lr: 1.5625e-05
Epoch 37/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.3709e-06 - mae: 0.0010 - val_loss: 2.1932e-05 - val_mae: 0.0031 - lr: 1.5625e-05
Epoch 38/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.4883e-06 - mae: 0.0010 - val_loss: 2.5918e-05 - val_mae: 0.0037 - lr: 1.5625e-05
Epoch 39/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.3460e-06 - mae: 0.0010 - val_loss: 2.7068e-05 - val_mae: 0.0036 - lr: 1.5625e-05
Epoch 40/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.2464e-06 - mae: 0.0010 - val_loss: 2.3400e-05 - val_mae: 0.0034 - lr: 7.8125e-06
Epoch 41/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.1856e-06 - mae: 0.0010 - val_loss: 2.0914e-05 - val_mae: 0.0030 - lr: 7.8125e-06
Epoch 42/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.1976e-06 - mae: 0.0010 - val_loss: 2.1060e-05 - val_mae: 0.0029 - lr: 7.8125e-06
Epoch 43/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.2143e-06 - mae: 0.0010 - val_loss: 2.3892e-05 - val_mae: 0.0033 - lr: 7.8125e-06
Epoch 44/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.2499e-06 - mae: 0.0010 - val_loss: 2.1173e-05 - val_mae: 0.0029 - lr: 7.8125e-06
Epoch 45/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.1165e-06 - mae: 0.0010 - val_loss: 2.0989e-05 - val_mae: 0.0029 - lr: 3.9063e-06
Epoch 46/50
1540/1540 [==============================] - 18s 12ms/step - loss: 9.1227e-06 - mae: 0.0010 - val_loss: 2.2046e-05 - val_mae: 0.0031 - lr: 3.9063e-06
Epoch 47/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.0909e-06 - mae: 0.0010 - val_loss: 2.0685e-05 - val_mae: 0.0030 - lr: 3.9063e-06
Epoch 48/50
1540/1540 [==============================] - 18s 11ms/step - loss: 9.0816e-06 - mae: 0.0010 - val_loss: 2.0818e-05 - val_mae: 0.0030 - lr: 3.9063e-06
Epoch 49/50
1540/1540 [==============================] - 25s 16ms/step - loss: 9.1571e-06 - mae: 0.0010 - val_loss: 2.1220e-05 - val_mae: 0.0031 - lr: 3.9063e-06
Epoch 50/50
1540/1540 [==============================] - 29s 19ms/step - loss: 9.0469e-06 - mae: 0.0010 - val_loss: 2.0632e-05 - val_mae: 0.0029 - lr: 1.9531e-06
428/428 [==============================] - 3s 5ms/step
Scaled MSE: 0.000021
Scaled RMSE: 0.004570
Scaled MAE: 0.002721
Original MSE: 7036.68
Original RMSE: 83.88
Original MAE: 49.95
/home/blackrukh/.local/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
Bitcoin price forecasting completed!