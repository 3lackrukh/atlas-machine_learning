blackrukh@3lackrukh:~/atlas-machine_learning/supervised_learning/time_series$ ./forecast_btc.py 
2025-03-29 22:44:05.515822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-29 22:44:05.515968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-29 22:44:05.519996: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-29 22:44:05.544303: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-29 22:44:06.650347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Bitcoin Price Forecasting with RNNs
=================================

Loaded data: X shape (69289, 24, 21), y shape (69289,)
Using target column: Close_log_ret for evaluation
Train set: (49887, 24, 21), (49887,)
Validation set: (5544, 24, 21), (5544,)
Test set: (13858, 24, 21), (13858,)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 bidirectional (Bidirection  (None, 64)                13824     
 al)                                                             
                                                                 
 dense (Dense)               (None, 1)                 65        
                                                                 
=================================================================
Total params: 13889 (54.25 KB)
Trainable params: 13889 (54.25 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/50
1559/1559 [==============================] - 36s 21ms/step - loss: 0.0224 - mae: 0.0686 - val_loss: 0.0064 - val_mae: 0.0584 - lr: 0.0010
Epoch 2/50
1559/1559 [==============================] - 32s 21ms/step - loss: 0.0060 - mae: 0.0475 - val_loss: 0.0046 - val_mae: 0.0532 - lr: 0.0010
Epoch 3/50
1559/1559 [==============================] - 32s 21ms/step - loss: 0.0050 - mae: 0.0438 - val_loss: 0.0029 - val_mae: 0.0349 - lr: 0.0010
Epoch 4/50
1559/1559 [==============================] - 32s 21ms/step - loss: 0.0048 - mae: 0.0421 - val_loss: 0.0037 - val_mae: 0.0447 - lr: 0.0010
Epoch 5/50
1559/1559 [==============================] - 32s 21ms/step - loss: 0.0045 - mae: 0.0405 - val_loss: 0.0028 - val_mae: 0.0336 - lr: 0.0010
Epoch 6/50
1559/1559 [==============================] - 34s 22ms/step - loss: 0.0044 - mae: 0.0395 - val_loss: 0.0026 - val_mae: 0.0318 - lr: 0.0010
Epoch 7/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0044 - mae: 0.0391 - val_loss: 0.0051 - val_mae: 0.0581 - lr: 0.0010
Epoch 8/50
1559/1559 [==============================] - 32s 21ms/step - loss: 0.0043 - mae: 0.0384 - val_loss: 0.0029 - val_mae: 0.0350 - lr: 0.0010
Epoch 9/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0043 - mae: 0.0381 - val_loss: 0.0031 - val_mae: 0.0398 - lr: 0.0010
Epoch 10/50
1559/1559 [==============================] - 34s 22ms/step - loss: 0.0043 - mae: 0.0380 - val_loss: 0.0030 - val_mae: 0.0357 - lr: 0.0010
Epoch 11/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0042 - mae: 0.0376 - val_loss: 0.0028 - val_mae: 0.0337 - lr: 0.0010
Epoch 12/50
1559/1559 [==============================] - 34s 22ms/step - loss: 0.0042 - mae: 0.0369 - val_loss: 0.0026 - val_mae: 0.0319 - lr: 5.0000e-04
Epoch 13/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0042 - mae: 0.0369 - val_loss: 0.0026 - val_mae: 0.0306 - lr: 5.0000e-04
Epoch 14/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0368 - val_loss: 0.0026 - val_mae: 0.0306 - lr: 5.0000e-04
Epoch 15/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0369 - val_loss: 0.0026 - val_mae: 0.0314 - lr: 5.0000e-04
Epoch 16/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0368 - val_loss: 0.0027 - val_mae: 0.0327 - lr: 5.0000e-04
Epoch 17/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0307 - lr: 2.5000e-04
Epoch 18/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0307 - lr: 2.5000e-04
Epoch 19/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0028 - val_mae: 0.0343 - lr: 2.5000e-04
Epoch 20/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0304 - lr: 2.5000e-04
Epoch 21/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0041 - mae: 0.0363 - val_loss: 0.0026 - val_mae: 0.0318 - lr: 2.5000e-04
Epoch 22/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0361 - val_loss: 0.0026 - val_mae: 0.0310 - lr: 1.2500e-04
Epoch 23/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0361 - val_loss: 0.0026 - val_mae: 0.0315 - lr: 1.2500e-04
Epoch 24/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0361 - val_loss: 0.0026 - val_mae: 0.0311 - lr: 1.2500e-04
Epoch 25/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0361 - val_loss: 0.0026 - val_mae: 0.0307 - lr: 1.2500e-04
Epoch 26/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0361 - val_loss: 0.0026 - val_mae: 0.0312 - lr: 1.2500e-04
Epoch 27/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0026 - val_mae: 0.0313 - lr: 6.2500e-05
Epoch 28/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0361 - val_loss: 0.0026 - val_mae: 0.0314 - lr: 6.2500e-05
Epoch 29/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0026 - val_mae: 0.0311 - lr: 6.2500e-05
Epoch 30/50
1559/1559 [==============================] - 33s 21ms/step - loss: 0.0040 - mae: 0.0360 - val_loss: 0.0026 - val_mae: 0.0312 - lr: 6.2500e-05
434/434 [==============================] - 5s 10ms/step
Scaled MSE (on log returns): 0.002069
Scaled RMSE (on log returns): 0.045486
Scaled MAE (on log returns): 0.024946
Starting price for conversion: $6689.04

Metrics on actual prices:
MSE: 136028.00
RMSE: 368.82
MAE: 138.69
MAPE: 0.45%
/home/blackrukh/.local/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
Bitcoin price forecasting completed!