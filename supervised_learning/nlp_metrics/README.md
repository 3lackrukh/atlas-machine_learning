This folder contains files created to practice implementing Bi-Lingual Evaluation Understudy (BLEU)
for evaluating Natural Language Processing (NLP) models. Each file represents a different method of
calculating BLEU scores, with a focus on unigram, n-gram, and cumulative BLEU scores. The files are
designed to be used as a starting point for implementing these methods in Python
