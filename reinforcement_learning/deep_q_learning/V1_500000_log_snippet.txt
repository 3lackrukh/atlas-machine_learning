 91981/100000: episode: 2367, duration: 2.919s, episode steps:  27, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.259 [0.000, 3.000],  loss: 0.001972, mae: 0.272051, mean_q: 0.381847, mean_eps: 0.917230
 92006/100000: episode: 2368, duration: 2.628s, episode steps:  25, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: 0.004262, mae: 0.268866, mean_q: 0.377058, mean_eps: 0.917206
 92064/100000: episode: 2369, duration: 4.879s, episode steps:  58, steps per second:  12, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.517 [0.000, 3.000],  loss: 0.003449, mae: 0.276062, mean_q: 0.387864, mean_eps: 0.917169
 92099/100000: episode: 2370, duration: 2.900s, episode steps:  35, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.486 [0.000, 3.000],  loss: 0.002230, mae: 0.276614, mean_q: 0.385391, mean_eps: 0.917127
 92127/100000: episode: 2371, duration: 2.959s, episode steps:  28, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: 0.002201, mae: 0.284720, mean_q: 0.395651, mean_eps: 0.917099
 92180/100000: episode: 2372, duration: 4.975s, episode steps:  53, steps per second:  11, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.755 [0.000, 3.000],  loss: 0.001879, mae: 0.261065, mean_q: 0.367531, mean_eps: 0.917062
 92208/100000: episode: 2373, duration: 2.328s, episode steps:  28, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.750 [0.000, 3.000],  loss: 0.003375, mae: 0.280557, mean_q: 0.396904, mean_eps: 0.917026
 92238/100000: episode: 2374, duration: 2.462s, episode steps:  30, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: 0.002020, mae: 0.262697, mean_q: 0.364862, mean_eps: 0.917000
 92268/100000: episode: 2375, duration: 2.844s, episode steps:  30, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.267 [0.000, 3.000],  loss: 0.003211, mae: 0.254334, mean_q: 0.357806, mean_eps: 0.916973
 92344/100000: episode: 2376, duration: 7.140s, episode steps:  76, steps per second:  11, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.500 [0.000, 3.000],  loss: 0.002167, mae: 0.255471, mean_q: 0.357443, mean_eps: 0.916925
 92372/100000: episode: 2377, duration: 2.258s, episode steps:  28, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.357 [0.000, 3.000],  loss: 0.002573, mae: 0.271367, mean_q: 0.384206, mean_eps: 0.916878
 92425/100000: episode: 2378, duration: 5.141s, episode steps:  53, steps per second:  10, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.491 [0.000, 3.000],  loss: 0.002804, mae: 0.278214, mean_q: 0.388968, mean_eps: 0.916842
 92464/100000: episode: 2379, duration: 3.786s, episode steps:  39, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: 0.002071, mae: 0.259608, mean_q: 0.362086, mean_eps: 0.916800
 92491/100000: episode: 2380, duration: 2.236s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: 0.002543, mae: 0.263002, mean_q: 0.367590, mean_eps: 0.916771
 92516/100000: episode: 2381, duration: 2.154s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: 0.003039, mae: 0.273596, mean_q: 0.383167, mean_eps: 0.916747
 92547/100000: episode: 2382, duration: 2.572s, episode steps:  31, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.290 [0.000, 3.000],  loss: 0.002765, mae: 0.254439, mean_q: 0.357732, mean_eps: 0.916722
 92619/100000: episode: 2383, duration: 7.220s, episode steps:  72, steps per second:  10, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.431 [0.000, 3.000],  loss: 0.002412, mae: 0.273709, mean_q: 0.378347, mean_eps: 0.916676
 92645/100000: episode: 2384, duration: 2.128s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: 0.002600, mae: 0.264068, mean_q: 0.371326, mean_eps: 0.916632
 92747/100000: episode: 2385, duration: 9.543s, episode steps: 102, steps per second:  11, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.735 [0.000, 3.000],  loss: 0.002253, mae: 0.256721, mean_q: 0.364163, mean_eps: 0.916574
 92850/100000: episode: 2386, duration: 8.340s, episode steps: 103, steps per second:  12, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.311 [0.000, 3.000],  loss: 0.001969, mae: 0.262364, mean_q: 0.365114, mean_eps: 0.916482
 92903/100000: episode: 2387, duration: 5.542s, episode steps:  53, steps per second:  10, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.585 [0.000, 3.000],  loss: 0.002047, mae: 0.274018, mean_q: 0.386610, mean_eps: 0.916412
 92930/100000: episode: 2388, duration: 2.280s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: 0.002282, mae: 0.243523, mean_q: 0.345224, mean_eps: 0.916376
 92955/100000: episode: 2389, duration: 2.118s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: 0.001983, mae: 0.269389, mean_q: 0.371577, mean_eps: 0.916352
 92980/100000: episode: 2390, duration: 2.074s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: 0.002422, mae: 0.260348, mean_q: 0.364918, mean_eps: 0.916330
 93045/100000: episode: 2391, duration: 6.516s, episode steps:  65, steps per second:  10, episode reward:  1.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.538 [0.000, 3.000],  loss: 0.002590, mae: 0.262371, mean_q: 0.368785, mean_eps: 0.916289
 93074/100000: episode: 2392, duration: 2.460s, episode steps:  29, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.483 [0.000, 3.000],  loss: 0.002490, mae: 0.259618, mean_q: 0.366248, mean_eps: 0.916247
 93100/100000: episode: 2393, duration: 2.207s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: 0.001714, mae: 0.265263, mean_q: 0.370505, mean_eps: 0.916222
 93174/100000: episode: 2394, duration: 7.123s, episode steps:  74, steps per second:  10, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.405 [0.000, 3.000],  loss: 0.001943, mae: 0.261935, mean_q: 0.367079, mean_eps: 0.916177
 93200/100000: episode: 2395, duration: 2.246s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.154 [0.000, 3.000],  loss: 0.003237, mae: 0.267441, mean_q: 0.370469, mean_eps: 0.916132
 93255/100000: episode: 2396, duration: 4.412s, episode steps:  55, steps per second:  12, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.473 [0.000, 3.000],  loss: 0.002551, mae: 0.262839, mean_q: 0.364104, mean_eps: 0.916096
 93292/100000: episode: 2397, duration: 3.046s, episode steps:  37, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.838 [0.000, 3.000],  loss: 0.001511, mae: 0.262598, mean_q: 0.361159, mean_eps: 0.916054
 93375/100000: episode: 2398, duration: 7.992s, episode steps:  83, steps per second:  10, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.361 [0.000, 3.000],  loss: 0.002057, mae: 0.271051, mean_q: 0.380268, mean_eps: 0.916000
 93401/100000: episode: 2399, duration: 2.248s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: 0.002145, mae: 0.258615, mean_q: 0.360313, mean_eps: 0.915951
 93432/100000: episode: 2400, duration: 2.598s, episode steps:  31, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.258 [0.000, 3.000],  loss: 0.002771, mae: 0.261187, mean_q: 0.364788, mean_eps: 0.915926
 93459/100000: episode: 2401, duration: 2.954s, episode steps:  27, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.926 [0.000, 3.000],  loss: 0.003069, mae: 0.275802, mean_q: 0.387952, mean_eps: 0.915899
 93487/100000: episode: 2402, duration: 2.967s, episode steps:  28, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: 0.001960, mae: 0.278751, mean_q: 0.389694, mean_eps: 0.915875
 93532/100000: episode: 2403, duration: 3.740s, episode steps:  45, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.578 [0.000, 3.000],  loss: 0.002527, mae: 0.269312, mean_q: 0.377690, mean_eps: 0.915842
 93560/100000: episode: 2404, duration: 2.389s, episode steps:  28, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.464 [0.000, 3.000],  loss: 0.002821, mae: 0.256685, mean_q: 0.361634, mean_eps: 0.915809
 93613/100000: episode: 2405, duration: 5.529s, episode steps:  53, steps per second:  10, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.585 [0.000, 3.000],  loss: 0.001621, mae: 0.269809, mean_q: 0.371568, mean_eps: 0.915773
 93650/100000: episode: 2406, duration: 3.267s, episode steps:  37, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.595 [0.000, 3.000],  loss: 0.002995, mae: 0.272985, mean_q: 0.383925, mean_eps: 0.915732
 93681/100000: episode: 2407, duration: 2.647s, episode steps:  31, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.548 [0.000, 3.000],  loss: 0.001883, mae: 0.286381, mean_q: 0.395908, mean_eps: 0.915701
 93707/100000: episode: 2408, duration: 2.137s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: 0.002332, mae: 0.271423, mean_q: 0.381618, mean_eps: 0.915676
 93733/100000: episode: 2409, duration: 2.240s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: 0.002604, mae: 0.271315, mean_q: 0.376326, mean_eps: 0.915652
 93766/100000: episode: 2410, duration: 4.070s, episode steps:  33, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.576 [0.000, 3.000],  loss: 0.001473, mae: 0.271668, mean_q: 0.387039, mean_eps: 0.915626
 93791/100000: episode: 2411, duration: 2.105s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: 0.002286, mae: 0.261155, mean_q: 0.363519, mean_eps: 0.915600
 93818/100000: episode: 2412, duration: 2.229s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: 0.003053, mae: 0.270038, mean_q: 0.378094, mean_eps: 0.915576
 93874/100000: episode: 2413, duration: 4.539s, episode steps:  56, steps per second:  12, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.446 [0.000, 3.000],  loss: 0.002202, mae: 0.257902, mean_q: 0.362245, mean_eps: 0.915539
 93905/100000: episode: 2414, duration: 3.824s, episode steps:  31, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.742 [0.000, 3.000],  loss: 0.001573, mae: 0.275729, mean_q: 0.387464, mean_eps: 0.915500
 93936/100000: episode: 2415, duration: 2.749s, episode steps:  31, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.839 [0.000, 3.000],  loss: 0.002002, mae: 0.273516, mean_q: 0.372963, mean_eps: 0.915472
 93963/100000: episode: 2416, duration: 2.225s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: 0.002695, mae: 0.253889, mean_q: 0.357022, mean_eps: 0.915446
 93998/100000: episode: 2417, duration: 2.876s, episode steps:  35, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.714 [0.000, 3.000],  loss: 0.001957, mae: 0.279311, mean_q: 0.391975, mean_eps: 0.915418
 94031/100000: episode: 2418, duration: 2.841s, episode steps:  33, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.818 [0.000, 3.000],  loss: 0.002441, mae: 0.258076, mean_q: 0.366406, mean_eps: 0.915387
 94056/100000: episode: 2419, duration: 3.262s, episode steps:  25, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: 0.001892, mae: 0.250339, mean_q: 0.347523, mean_eps: 0.915361
 94086/100000: episode: 2420, duration: 2.495s, episode steps:  30, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: 0.002373, mae: 0.251683, mean_q: 0.351767, mean_eps: 0.915337
 94162/100000: episode: 2421, duration: 6.157s, episode steps:  76, steps per second:  12, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.566 [0.000, 3.000],  loss: 0.002190, mae: 0.268267, mean_q: 0.375347, mean_eps: 0.915289
 94218/100000: episode: 2422, duration: 5.977s, episode steps:  56, steps per second:   9, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.696 [0.000, 3.000],  loss: 0.002302, mae: 0.280621, mean_q: 0.390666, mean_eps: 0.915229
 94271/100000: episode: 2423, duration: 4.398s, episode steps:  53, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.679 [0.000, 3.000],  loss: 0.002189, mae: 0.270201, mean_q: 0.382960, mean_eps: 0.915180
 94296/100000: episode: 2424, duration: 2.160s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: 0.001522, mae: 0.255404, mean_q: 0.356328, mean_eps: 0.915145
 94323/100000: episode: 2425, duration: 2.450s, episode steps:  27, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: 0.002549, mae: 0.267479, mean_q: 0.373311, mean_eps: 0.915122
 94348/100000: episode: 2426, duration: 3.275s, episode steps:  25, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: 0.002820, mae: 0.270599, mean_q: 0.385126, mean_eps: 0.915099
 94379/100000: episode: 2427, duration: 2.651s, episode steps:  31, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.548 [0.000, 3.000],  loss: 0.001617, mae: 0.274969, mean_q: 0.383243, mean_eps: 0.915073
 94433/100000: episode: 2428, duration: 4.490s, episode steps:  54, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.481 [0.000, 3.000],  loss: 0.002648, mae: 0.273225, mean_q: 0.382872, mean_eps: 0.915035
 94488/100000: episode: 2429, duration: 5.881s, episode steps:  55, steps per second:   9, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.473 [0.000, 3.000],  loss: 0.002858, mae: 0.265919, mean_q: 0.370998, mean_eps: 0.914986
 94564/100000: episode: 2430, duration: 6.453s, episode steps:  76, steps per second:  12, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.684 [0.000, 3.000],  loss: 0.001502, mae: 0.262450, mean_q: 0.368613, mean_eps: 0.914927
 94602/100000: episode: 2431, duration: 3.203s, episode steps:  38, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.368 [0.000, 3.000],  loss: 0.002347, mae: 0.272065, mean_q: 0.378512, mean_eps: 0.914876
 94627/100000: episode: 2432, duration: 3.329s, episode steps:  25, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.920 [0.000, 3.000],  loss: 0.001785, mae: 0.267311, mean_q: 0.383120, mean_eps: 0.914847
 94652/100000: episode: 2433, duration: 2.374s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: 0.001614, mae: 0.277132, mean_q: 0.385863, mean_eps: 0.914825
 94679/100000: episode: 2434, duration: 2.302s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.222 [0.000, 3.000],  loss: 0.001468, mae: 0.277386, mean_q: 0.393767, mean_eps: 0.914802
 94706/100000: episode: 2435, duration: 2.268s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: 0.002370, mae: 0.260790, mean_q: 0.364346, mean_eps: 0.914777
 94732/100000: episode: 2436, duration: 2.235s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: 0.003000, mae: 0.255360, mean_q: 0.363600, mean_eps: 0.914753
 94763/100000: episode: 2437, duration: 3.619s, episode steps:  31, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.774 [0.000, 3.000],  loss: 0.002466, mae: 0.278114, mean_q: 0.393753, mean_eps: 0.914728
 94796/100000: episode: 2438, duration: 3.327s, episode steps:  33, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.242 [0.000, 3.000],  loss: 0.002990, mae: 0.267696, mean_q: 0.374802, mean_eps: 0.914699
 94821/100000: episode: 2439, duration: 2.193s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: 0.001470, mae: 0.250872, mean_q: 0.355222, mean_eps: 0.914673
 94874/100000: episode: 2440, duration: 4.569s, episode steps:  53, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.623 [0.000, 3.000],  loss: 0.001868, mae: 0.260685, mean_q: 0.362522, mean_eps: 0.914638
 94899/100000: episode: 2441, duration: 2.926s, episode steps:  25, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.000 [0.000, 3.000],  loss: 0.001652, mae: 0.248169, mean_q: 0.349520, mean_eps: 0.914603
 94925/100000: episode: 2442, duration: 2.880s, episode steps:  26, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: 0.001699, mae: 0.254687, mean_q: 0.356663, mean_eps: 0.914580
 94979/100000: episode: 2443, duration: 4.579s, episode steps:  54, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.352 [0.000, 3.000],  loss: 0.002165, mae: 0.262022, mean_q: 0.367662, mean_eps: 0.914544
 95004/100000: episode: 2444, duration: 2.181s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: 0.002441, mae: 0.270334, mean_q: 0.382766, mean_eps: 0.914508
 95029/100000: episode: 2445, duration: 2.453s, episode steps:  25, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.920 [0.000, 3.000],  loss: 0.001217, mae: 0.263964, mean_q: 0.372018, mean_eps: 0.914486
 95104/100000: episode: 2446, duration: 7.331s, episode steps:  75, steps per second:  10, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.880 [0.000, 3.000],  loss: 0.001484, mae: 0.257017, mean_q: 0.362815, mean_eps: 0.914441
 95225/100000: episode: 2447, duration: 11.162s, episode steps: 121, steps per second:  11, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.587 [0.000, 3.000],  loss: 0.001996, mae: 0.260650, mean_q: 0.368729, mean_eps: 0.914352
 95280/100000: episode: 2448, duration: 4.616s, episode steps:  55, steps per second:  12, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.709 [0.000, 3.000],  loss: 0.001901, mae: 0.250131, mean_q: 0.354784, mean_eps: 0.914273
 95316/100000: episode: 2449, duration: 3.056s, episode steps:  36, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: 0.001533, mae: 0.243769, mean_q: 0.340360, mean_eps: 0.914232
 95369/100000: episode: 2450, duration: 5.717s, episode steps:  53, steps per second:   9, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.623 [0.000, 3.000],  loss: 0.001762, mae: 0.262203, mean_q: 0.367753, mean_eps: 0.914192
 95397/100000: episode: 2451, duration: 2.471s, episode steps:  28, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.179 [0.000, 3.000],  loss: 0.002408, mae: 0.255474, mean_q: 0.358043, mean_eps: 0.914156
 95423/100000: episode: 2452, duration: 2.162s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.692 [0.000, 3.000],  loss: 0.002238, mae: 0.285513, mean_q: 0.398143, mean_eps: 0.914131
 95451/100000: episode: 2453, duration: 2.357s, episode steps:  28, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.536 [0.000, 3.000],  loss: 0.002332, mae: 0.270271, mean_q: 0.386063, mean_eps: 0.914107
 95483/100000: episode: 2454, duration: 3.881s, episode steps:  32, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.562 [0.000, 3.000],  loss: 0.001597, mae: 0.280177, mean_q: 0.398581, mean_eps: 0.914080
 95508/100000: episode: 2455, duration: 2.378s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: 0.001482, mae: 0.260901, mean_q: 0.373315, mean_eps: 0.914054
 95533/100000: episode: 2456, duration: 2.108s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: 0.001811, mae: 0.279468, mean_q: 0.394193, mean_eps: 0.914032
 95610/100000: episode: 2457, duration: 6.643s, episode steps:  77, steps per second:  12, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.584 [0.000, 3.000],  loss: 0.001920, mae: 0.269447, mean_q: 0.378179, mean_eps: 0.913986
 95636/100000: episode: 2458, duration: 3.298s, episode steps:  26, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: 0.002714, mae: 0.257056, mean_q: 0.358618, mean_eps: 0.913940
 95665/100000: episode: 2459, duration: 2.413s, episode steps:  29, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.517 [0.000, 3.000],  loss: 0.003224, mae: 0.271799, mean_q: 0.378768, mean_eps: 0.913915
 95692/100000: episode: 2460, duration: 2.237s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: 0.001607, mae: 0.266425, mean_q: 0.369441, mean_eps: 0.913890
 95718/100000: episode: 2461, duration: 2.265s, episode steps:  26, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: 0.001995, mae: 0.250539, mean_q: 0.355071, mean_eps: 0.913866
 95750/100000: episode: 2462, duration: 2.689s, episode steps:  32, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: 0.002187, mae: 0.274108, mean_q: 0.388225, mean_eps: 0.913840
 95780/100000: episode: 2463, duration: 3.766s, episode steps:  30, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: 0.001727, mae: 0.270051, mean_q: 0.377377, mean_eps: 0.913812
 95836/100000: episode: 2464, duration: 4.642s, episode steps:  56, steps per second:  12, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.679 [0.000, 3.000],  loss: 0.001670, mae: 0.257903, mean_q: 0.362371, mean_eps: 0.913773
 95862/100000: episode: 2465, duration: 2.275s, episode steps:  26, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: 0.002002, mae: 0.265120, mean_q: 0.371129, mean_eps: 0.913736
 95889/100000: episode: 2466, duration: 2.309s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: 0.001434, mae: 0.276824, mean_q: 0.396281, mean_eps: 0.913713
 95915/100000: episode: 2467, duration: 3.412s, episode steps:  26, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: 0.001294, mae: 0.267906, mean_q: 0.375524, mean_eps: 0.913689
 95968/100000: episode: 2468, duration: 4.484s, episode steps:  53, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.377 [0.000, 3.000],  loss: 0.001974, mae: 0.273294, mean_q: 0.384883, mean_eps: 0.913653
 96040/100000: episode: 2469, duration: 5.933s, episode steps:  72, steps per second:  12, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.833 [0.000, 3.000],  loss: 0.002449, mae: 0.272088, mean_q: 0.379870, mean_eps: 0.913597
 96100/100000: episode: 2470, duration: 6.170s, episode steps:  60, steps per second:  10, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.500 [0.000, 3.000],  loss: 0.002099, mae: 0.266880, mean_q: 0.378303, mean_eps: 0.913537
 96125/100000: episode: 2471, duration: 2.109s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: 0.001793, mae: 0.264314, mean_q: 0.366847, mean_eps: 0.913499
 96190/100000: episode: 2472, duration: 5.492s, episode steps:  65, steps per second:  12, episode reward:  1.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.492 [0.000, 3.000],  loss: 0.001825, mae: 0.280846, mean_q: 0.395647, mean_eps: 0.913459
 96262/100000: episode: 2473, duration: 7.145s, episode steps:  72, steps per second:  10, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.556 [0.000, 3.000],  loss: 0.002247, mae: 0.267522, mean_q: 0.377619, mean_eps: 0.913397
 96289/100000: episode: 2474, duration: 2.279s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.000 [0.000, 3.000],  loss: 0.001555, mae: 0.252165, mean_q: 0.358042, mean_eps: 0.913353
 96314/100000: episode: 2475, duration: 2.130s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: 0.002081, mae: 0.263407, mean_q: 0.370953, mean_eps: 0.913329
 96387/100000: episode: 2476, duration: 7.293s, episode steps:  73, steps per second:  10, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.452 [0.000, 3.000],  loss: 0.002012, mae: 0.268910, mean_q: 0.379833, mean_eps: 0.913285
 96416/100000: episode: 2477, duration: 2.468s, episode steps:  29, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.552 [0.000, 3.000],  loss: 0.001756, mae: 0.261275, mean_q: 0.364093, mean_eps: 0.913239
 96441/100000: episode: 2478, duration: 2.162s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: 0.002320, mae: 0.274904, mean_q: 0.384737, mean_eps: 0.913215
 96468/100000: episode: 2479, duration: 2.252s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.704 [0.000, 3.000],  loss: 0.002343, mae: 0.259635, mean_q: 0.359940, mean_eps: 0.913191
 96493/100000: episode: 2480, duration: 3.080s, episode steps:  25, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: 0.001383, mae: 0.262094, mean_q: 0.371313, mean_eps: 0.913168
 96519/100000: episode: 2481, duration: 2.603s, episode steps:  26, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.962 [0.000, 3.000],  loss: 0.002282, mae: 0.258288, mean_q: 0.362260, mean_eps: 0.913145
 96551/100000: episode: 2482, duration: 2.616s, episode steps:  32, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.531 [0.000, 3.000],  loss: 0.001640, mae: 0.254125, mean_q: 0.358910, mean_eps: 0.913119
 96579/100000: episode: 2483, duration: 2.372s, episode steps:  28, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.821 [0.000, 3.000],  loss: 0.001767, mae: 0.271047, mean_q: 0.384619, mean_eps: 0.913092
 96609/100000: episode: 2484, duration: 2.489s, episode steps:  30, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.533 [0.000, 3.000],  loss: 0.002408, mae: 0.262065, mean_q: 0.366546, mean_eps: 0.913066
 96645/100000: episode: 2485, duration: 4.134s, episode steps:  36, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: 0.002169, mae: 0.269949, mean_q: 0.373079, mean_eps: 0.913036
 96671/100000: episode: 2486, duration: 2.278s, episode steps:  26, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.692 [0.000, 3.000],  loss: 0.001683, mae: 0.260591, mean_q: 0.368104, mean_eps: 0.913008
 96733/100000: episode: 2487, duration: 5.108s, episode steps:  62, steps per second:  12, episode reward:  1.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.581 [0.000, 3.000],  loss: 0.002287, mae: 0.260688, mean_q: 0.371162, mean_eps: 0.912969
 96758/100000: episode: 2488, duration: 2.037s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: 0.001869, mae: 0.261610, mean_q: 0.368425, mean_eps: 0.912929
 96783/100000: episode: 2489, duration: 2.700s, episode steps:  25, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: 0.001763, mae: 0.273958, mean_q: 0.382190, mean_eps: 0.912907
 96808/100000: episode: 2490, duration: 2.701s, episode steps:  25, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: 0.002259, mae: 0.245170, mean_q: 0.332107, mean_eps: 0.912884
 96837/100000: episode: 2491, duration: 2.445s, episode steps:  29, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: 0.002502, mae: 0.262062, mean_q: 0.364171, mean_eps: 0.912860
 96862/100000: episode: 2492, duration: 2.077s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: 0.002269, mae: 0.266959, mean_q: 0.373496, mean_eps: 0.912836
 96915/100000: episode: 2493, duration: 4.298s, episode steps:  53, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.453 [0.000, 3.000],  loss: 0.001924, mae: 0.267550, mean_q: 0.373461, mean_eps: 0.912801
 96943/100000: episode: 2494, duration: 3.579s, episode steps:  28, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.714 [0.000, 3.000],  loss: 0.001843, mae: 0.255964, mean_q: 0.361356, mean_eps: 0.912764
 97021/100000: episode: 2495, duration: 6.406s, episode steps:  78, steps per second:  12, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.295 [0.000, 3.000],  loss: 0.002060, mae: 0.264984, mean_q: 0.371523, mean_eps: 0.912717
 97141/100000: episode: 2496, duration: 10.908s, episode steps: 120, steps per second:  11, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.467 [0.000, 3.000],  loss: 0.001481, mae: 0.267771, mean_q: 0.375585, mean_eps: 0.912628
 97166/100000: episode: 2497, duration: 2.046s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: 0.001192, mae: 0.263605, mean_q: 0.375249, mean_eps: 0.912562
 97191/100000: episode: 2498, duration: 2.062s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: 0.001934, mae: 0.271448, mean_q: 0.380194, mean_eps: 0.912540
 97218/100000: episode: 2499, duration: 2.348s, episode steps:  27, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: 0.002013, mae: 0.254917, mean_q: 0.359652, mean_eps: 0.912516
 97244/100000: episode: 2500, duration: 3.453s, episode steps:  26, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: 0.001848, mae: 0.274044, mean_q: 0.380037, mean_eps: 0.912493
 97269/100000: episode: 2501, duration: 2.066s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: 0.002222, mae: 0.272465, mean_q: 0.385881, mean_eps: 0.912470
 97294/100000: episode: 2502, duration: 2.102s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: 0.001460, mae: 0.258862, mean_q: 0.361778, mean_eps: 0.912447
 97349/100000: episode: 2503, duration: 4.475s, episode steps:  55, steps per second:  12, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.436 [0.000, 3.000],  loss: 0.001668, mae: 0.275565, mean_q: 0.384744, mean_eps: 0.912411
 97375/100000: episode: 2504, duration: 2.894s, episode steps:  26, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: 0.001160, mae: 0.264559, mean_q: 0.377281, mean_eps: 0.912375
 97400/100000: episode: 2505, duration: 2.749s, episode steps:  25, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: 0.001412, mae: 0.263658, mean_q: 0.373122, mean_eps: 0.912352
 97426/100000: episode: 2506, duration: 2.227s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: 0.001310, mae: 0.273512, mean_q: 0.379293, mean_eps: 0.912329
 97503/100000: episode: 2507, duration: 6.292s, episode steps:  77, steps per second:  12, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.506 [0.000, 3.000],  loss: 0.002604, mae: 0.276875, mean_q: 0.386306, mean_eps: 0.912282
 97557/100000: episode: 2508, duration: 5.706s, episode steps:  54, steps per second:   9, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.222 [0.000, 3.000],  loss: 0.001889, mae: 0.262825, mean_q: 0.369936, mean_eps: 0.912223
 97617/100000: episode: 2509, duration: 4.908s, episode steps:  60, steps per second:  12, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.700 [0.000, 3.000],  loss: 0.001789, mae: 0.255963, mean_q: 0.359549, mean_eps: 0.912172
 97670/100000: episode: 2510, duration: 5.306s, episode steps:  53, steps per second:  10, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.434 [0.000, 3.000],  loss: 0.001721, mae: 0.256320, mean_q: 0.362618, mean_eps: 0.912121
 97695/100000: episode: 2511, duration: 2.647s, episode steps:  25, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: 0.002132, mae: 0.258533, mean_q: 0.363696, mean_eps: 0.912086
 97723/100000: episode: 2512, duration: 2.414s, episode steps:  28, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.821 [0.000, 3.000],  loss: 0.001675, mae: 0.252572, mean_q: 0.353523, mean_eps: 0.912062
 97750/100000: episode: 2513, duration: 2.284s, episode steps:  27, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.889 [0.000, 3.000],  loss: 0.002986, mae: 0.256597, mean_q: 0.367169, mean_eps: 0.912038
 97775/100000: episode: 2514, duration: 2.188s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: 0.001944, mae: 0.266298, mean_q: 0.378075, mean_eps: 0.912014
 97876/100000: episode: 2515, duration: 9.685s, episode steps: 101, steps per second:  10, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.535 [0.000, 3.000],  loss: 0.001217, mae: 0.265581, mean_q: 0.374543, mean_eps: 0.911958
 98030/100000: episode: 2516, duration: 14.260s, episode steps: 154, steps per second:  11, episode reward:  3.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.643 [0.000, 3.000],  loss: 0.001723, mae: 0.264836, mean_q: 0.373452, mean_eps: 0.911843
 98084/100000: episode: 2517, duration: 4.509s, episode steps:  54, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.204 [0.000, 3.000],  loss: 0.002127, mae: 0.261934, mean_q: 0.366358, mean_eps: 0.911749
 98190/100000: episode: 2518, duration: 10.042s, episode steps: 106, steps per second:  11, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.425 [0.000, 3.000],  loss: 0.001896, mae: 0.261450, mean_q: 0.368648, mean_eps: 0.911677
 98215/100000: episode: 2519, duration: 2.141s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: 0.001441, mae: 0.242227, mean_q: 0.341949, mean_eps: 0.911618
 98290/100000: episode: 2520, duration: 7.677s, episode steps:  75, steps per second:  10, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.387 [0.000, 3.000],  loss: 0.002072, mae: 0.255840, mean_q: 0.365399, mean_eps: 0.911573
 98347/100000: episode: 2521, duration: 4.774s, episode steps:  57, steps per second:  12, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.351 [0.000, 3.000],  loss: 0.001483, mae: 0.264963, mean_q: 0.375869, mean_eps: 0.911514
 98373/100000: episode: 2522, duration: 2.242s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: 0.001654, mae: 0.280815, mean_q: 0.391271, mean_eps: 0.911476
 98429/100000: episode: 2523, duration: 5.990s, episode steps:  56, steps per second:   9, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.500 [0.000, 3.000],  loss: 0.001479, mae: 0.264953, mean_q: 0.371812, mean_eps: 0.911440
 98502/100000: episode: 2524, duration: 6.187s, episode steps:  73, steps per second:  12, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.671 [0.000, 3.000],  loss: 0.001828, mae: 0.264265, mean_q: 0.372813, mean_eps: 0.911382
 98529/100000: episode: 2525, duration: 2.896s, episode steps:  27, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: 0.001175, mae: 0.257033, mean_q: 0.362049, mean_eps: 0.911336
 98559/100000: episode: 2526, duration: 3.386s, episode steps:  30, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.300 [0.000, 3.000],  loss: 0.001875, mae: 0.267634, mean_q: 0.374210, mean_eps: 0.911311
 98585/100000: episode: 2527, duration: 2.250s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.692 [0.000, 3.000],  loss: 0.001898, mae: 0.265096, mean_q: 0.372619, mean_eps: 0.911286
 98610/100000: episode: 2528, duration: 2.137s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: 0.001517, mae: 0.272140, mean_q: 0.387042, mean_eps: 0.911263
 98663/100000: episode: 2529, duration: 4.667s, episode steps:  53, steps per second:  11, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.736 [0.000, 3.000],  loss: 0.002034, mae: 0.265289, mean_q: 0.370679, mean_eps: 0.911228
 98743/100000: episode: 2530, duration: 7.732s, episode steps:  80, steps per second:  10, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.637 [0.000, 3.000],  loss: 0.001905, mae: 0.262289, mean_q: 0.369600, mean_eps: 0.911168
 98818/100000: episode: 2531, duration: 7.079s, episode steps:  75, steps per second:  11, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.547 [0.000, 3.000],  loss: 0.002219, mae: 0.265669, mean_q: 0.377024, mean_eps: 0.911098
 98850/100000: episode: 2532, duration: 3.239s, episode steps:  32, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.406 [0.000, 3.000],  loss: 0.002787, mae: 0.262383, mean_q: 0.373264, mean_eps: 0.911050
 98884/100000: episode: 2533, duration: 2.931s, episode steps:  34, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.618 [0.000, 3.000],  loss: 0.002269, mae: 0.267399, mean_q: 0.374948, mean_eps: 0.911020
 98911/100000: episode: 2534, duration: 2.383s, episode steps:  27, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: 0.001490, mae: 0.268364, mean_q: 0.378493, mean_eps: 0.910993
 98937/100000: episode: 2535, duration: 2.291s, episode steps:  26, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: 0.002197, mae: 0.250107, mean_q: 0.346915, mean_eps: 0.910969
 98963/100000: episode: 2536, duration: 3.244s, episode steps:  26, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: 0.003312, mae: 0.267960, mean_q: 0.377397, mean_eps: 0.910945
 98989/100000: episode: 2537, duration: 2.523s, episode steps:  26, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: 0.001618, mae: 0.259998, mean_q: 0.369572, mean_eps: 0.910922
 99019/100000: episode: 2538, duration: 2.682s, episode steps:  30, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.467 [0.000, 3.000],  loss: 0.001419, mae: 0.277691, mean_q: 0.388233, mean_eps: 0.910897
 99056/100000: episode: 2539, duration: 3.238s, episode steps:  37, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.486 [0.000, 3.000],  loss: 0.002498, mae: 0.254299, mean_q: 0.356855, mean_eps: 0.910867
 99083/100000: episode: 2540, duration: 2.444s, episode steps:  27, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: 0.002116, mae: 0.265250, mean_q: 0.378634, mean_eps: 0.910838
 99138/100000: episode: 2541, duration: 6.073s, episode steps:  55, steps per second:   9, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.818 [0.000, 3.000],  loss: 0.001731, mae: 0.267524, mean_q: 0.374731, mean_eps: 0.910801
 99163/100000: episode: 2542, duration: 2.208s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: 0.001287, mae: 0.261847, mean_q: 0.367093, mean_eps: 0.910765
 99188/100000: episode: 2543, duration: 2.207s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: 0.001601, mae: 0.260809, mean_q: 0.365889, mean_eps: 0.910742
 99216/100000: episode: 2544, duration: 2.461s, episode steps:  28, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.929 [0.000, 3.000],  loss: 0.002849, mae: 0.266047, mean_q: 0.379665, mean_eps: 0.910719
 99243/100000: episode: 2545, duration: 3.326s, episode steps:  27, steps per second:   8, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: 0.002537, mae: 0.256559, mean_q: 0.365700, mean_eps: 0.910694
 99271/100000: episode: 2546, duration: 2.560s, episode steps:  28, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.286 [0.000, 3.000],  loss: 0.001159, mae: 0.267089, mean_q: 0.374801, mean_eps: 0.910669
 99325/100000: episode: 2547, duration: 4.418s, episode steps:  54, steps per second:  12, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.796 [0.000, 3.000],  loss: 0.003004, mae: 0.272356, mean_q: 0.388179, mean_eps: 0.910632
 99350/100000: episode: 2548, duration: 2.118s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: 0.001620, mae: 0.259848, mean_q: 0.370054, mean_eps: 0.910597
 99425/100000: episode: 2549, duration: 7.425s, episode steps:  75, steps per second:  10, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.653 [0.000, 3.000],  loss: 0.001702, mae: 0.259796, mean_q: 0.368923, mean_eps: 0.910552
 99451/100000: episode: 2550, duration: 2.231s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.154 [0.000, 3.000],  loss: 0.002107, mae: 0.276395, mean_q: 0.382904, mean_eps: 0.910506
 99476/100000: episode: 2551, duration: 2.156s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: 0.001253, mae: 0.246924, mean_q: 0.347579, mean_eps: 0.910483
 99504/100000: episode: 2552, duration: 2.335s, episode steps:  28, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.607 [0.000, 3.000],  loss: 0.002730, mae: 0.254490, mean_q: 0.357839, mean_eps: 0.910459
 99529/100000: episode: 2553, duration: 2.871s, episode steps:  25, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: 0.001181, mae: 0.258275, mean_q: 0.365628, mean_eps: 0.910436
 99554/100000: episode: 2554, duration: 2.791s, episode steps:  25, steps per second:   9, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: 0.002568, mae: 0.268384, mean_q: 0.379749, mean_eps: 0.910413
 99579/100000: episode: 2555, duration: 2.203s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: 0.002474, mae: 0.232768, mean_q: 0.338094, mean_eps: 0.910391
 99605/100000: episode: 2556, duration: 2.152s, episode steps:  26, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.692 [0.000, 3.000],  loss: 0.001507, mae: 0.266522, mean_q: 0.379225, mean_eps: 0.910368
 99635/100000: episode: 2557, duration: 2.508s, episode steps:  30, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.567 [0.000, 3.000],  loss: 0.002189, mae: 0.262312, mean_q: 0.370608, mean_eps: 0.910342
 99743/100000: episode: 2558, duration: 10.217s, episode steps: 108, steps per second:  11, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.611 [0.000, 3.000],  loss: 0.002008, mae: 0.259622, mean_q: 0.366850, mean_eps: 0.910280
 99768/100000: episode: 2559, duration: 2.141s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: 0.002000, mae: 0.282526, mean_q: 0.396988, mean_eps: 0.910220
 99845/100000: episode: 2560, duration: 7.694s, episode steps:  77, steps per second:  10, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.688 [0.000, 3.000],  loss: 0.001973, mae: 0.276425, mean_q: 0.391674, mean_eps: 0.910175
 99870/100000: episode: 2561, duration: 2.181s, episode steps:  25, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: 0.002100, mae: 0.252824, mean_q: 0.356599, mean_eps: 0.910129
 99902/100000: episode: 2562, duration: 2.724s, episode steps:  32, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.406 [0.000, 3.000],  loss: 0.002478, mae: 0.276509, mean_q: 0.391273, mean_eps: 0.910103
 99927/100000: episode: 2563, duration: 2.133s, episode steps:  25, steps per second:  12, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.160 [1.000, 3.000],  loss: 0.001552, mae: 0.254899, mean_q: 0.357107, mean_eps: 0.910077
 99953/100000: episode: 2564, duration: 2.610s, episode steps:  26, steps per second:  10, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: 0.001322, mae: 0.256302, mean_q: 0.365316, mean_eps: 0.910054
done, took 4812.968 seconds
Model saved at step 600000 to /content/drive/MyDrive/breakout_dqn/breakout_dqn_weights_600000.h5
Training for 100000 steps ...
   104/100000: episode: 1, duration: 0.298s, episode steps: 104, steps per second: 349, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   159/100000: episode: 2, duration: 0.171s, episode steps:  55, steps per second: 322, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.455 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   185/100000: episode: 3, duration: 0.097s, episode steps:  26, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   216/100000: episode: 4, duration: 0.112s, episode steps:  31, steps per second: 277, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.581 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   316/100000: episode: 5, duration: 0.283s, episode steps: 100, steps per second: 354, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   352/100000: episode: 6, duration: 0.108s, episode steps:  36, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.278 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   391/100000: episode: 7, duration: 0.120s, episode steps:  39, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.359 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   417/100000: episode: 8, duration: 0.084s, episode steps:  26, steps per second: 310, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   442/100000: episode: 9, duration: 0.086s, episode steps:  25, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   467/100000: episode: 10, duration: 0.095s, episode steps:  25, steps per second: 262, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   549/100000: episode: 11, duration: 0.230s, episode steps:  82, steps per second: 356, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.622 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   574/100000: episode: 12, duration: 0.080s, episode steps:  25, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   601/100000: episode: 13, duration: 0.086s, episode steps:  27, steps per second: 315, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   626/100000: episode: 14, duration: 0.086s, episode steps:  25, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   655/100000: episode: 15, duration: 0.088s, episode steps:  29, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   685/100000: episode: 16, duration: 0.089s, episode steps:  30, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.067 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   711/100000: episode: 17, duration: 0.088s, episode steps:  26, steps per second: 297, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   750/100000: episode: 18, duration: 0.113s, episode steps:  39, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.436 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   779/100000: episode: 19, duration: 0.106s, episode steps:  29, steps per second: 274, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   806/100000: episode: 20, duration: 0.088s, episode steps:  27, steps per second: 306, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   832/100000: episode: 21, duration: 0.082s, episode steps:  26, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
   990/100000: episode: 22, duration: 0.435s, episode steps: 158, steps per second: 363, episode reward:  3.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1017/100000: episode: 23, duration: 0.084s, episode steps:  27, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.185 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1043/100000: episode: 24, duration: 0.077s, episode steps:  26, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1071/100000: episode: 25, duration: 0.095s, episode steps:  28, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1097/100000: episode: 26, duration: 0.081s, episode steps:  26, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1202/100000: episode: 27, duration: 0.308s, episode steps: 105, steps per second: 341, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.390 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1228/100000: episode: 28, duration: 0.081s, episode steps:  26, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.308 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1255/100000: episode: 29, duration: 0.079s, episode steps:  27, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1280/100000: episode: 30, duration: 0.088s, episode steps:  25, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1307/100000: episode: 31, duration: 0.083s, episode steps:  27, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1335/100000: episode: 32, duration: 0.086s, episode steps:  28, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.893 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1360/100000: episode: 33, duration: 0.092s, episode steps:  25, steps per second: 272, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1389/100000: episode: 34, duration: 0.088s, episode steps:  29, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.172 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1416/100000: episode: 35, duration: 0.082s, episode steps:  27, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1442/100000: episode: 36, duration: 0.098s, episode steps:  26, steps per second: 264, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1472/100000: episode: 37, duration: 0.097s, episode steps:  30, steps per second: 308, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.733 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1499/100000: episode: 38, duration: 0.081s, episode steps:  27, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.778 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1526/100000: episode: 39, duration: 0.089s, episode steps:  27, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1553/100000: episode: 40, duration: 0.082s, episode steps:  27, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1584/100000: episode: 41, duration: 0.093s, episode steps:  31, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.806 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1614/100000: episode: 42, duration: 0.100s, episode steps:  30, steps per second: 299, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.700 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1687/100000: episode: 43, duration: 0.198s, episode steps:  73, steps per second: 369, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.795 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1713/100000: episode: 44, duration: 0.088s, episode steps:  26, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1738/100000: episode: 45, duration: 0.078s, episode steps:  25, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1791/100000: episode: 46, duration: 0.173s, episode steps:  53, steps per second: 306, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.604 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1816/100000: episode: 47, duration: 0.078s, episode steps:  25, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.080 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1845/100000: episode: 48, duration: 0.085s, episode steps:  29, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1871/100000: episode: 49, duration: 0.088s, episode steps:  26, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1896/100000: episode: 50, duration: 0.076s, episode steps:  25, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  1970/100000: episode: 51, duration: 0.219s, episode steps:  74, steps per second: 338, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.608 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2071/100000: episode: 52, duration: 0.278s, episode steps: 101, steps per second: 363, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.277 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2096/100000: episode: 53, duration: 0.077s, episode steps:  25, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2121/100000: episode: 54, duration: 0.081s, episode steps:  25, steps per second: 309, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2152/100000: episode: 55, duration: 0.114s, episode steps:  31, steps per second: 273, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.355 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2227/100000: episode: 56, duration: 0.204s, episode steps:  75, steps per second: 368, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.413 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2256/100000: episode: 57, duration: 0.100s, episode steps:  29, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.517 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2327/100000: episode: 58, duration: 0.198s, episode steps:  71, steps per second: 358, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.507 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2363/100000: episode: 59, duration: 0.118s, episode steps:  36, steps per second: 306, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2434/100000: episode: 60, duration: 0.195s, episode steps:  71, steps per second: 365, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.521 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2459/100000: episode: 61, duration: 0.097s, episode steps:  25, steps per second: 258, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2514/100000: episode: 62, duration: 0.233s, episode steps:  55, steps per second: 236, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.582 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2544/100000: episode: 63, duration: 0.157s, episode steps:  30, steps per second: 192, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.733 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2644/100000: episode: 64, duration: 0.396s, episode steps: 100, steps per second: 253, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.430 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2669/100000: episode: 65, duration: 0.113s, episode steps:  25, steps per second: 221, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2804/100000: episode: 66, duration: 0.538s, episode steps: 135, steps per second: 251, episode reward:  3.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.452 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2829/100000: episode: 67, duration: 0.115s, episode steps:  25, steps per second: 218, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2884/100000: episode: 68, duration: 0.250s, episode steps:  55, steps per second: 220, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.527 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  2911/100000: episode: 69, duration: 0.120s, episode steps:  27, steps per second: 226, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.074 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3012/100000: episode: 70, duration: 0.409s, episode steps: 101, steps per second: 247, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.535 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3056/100000: episode: 71, duration: 0.250s, episode steps:  44, steps per second: 176, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.341 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3083/100000: episode: 72, duration: 0.134s, episode steps:  27, steps per second: 202, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3108/100000: episode: 73, duration: 0.123s, episode steps:  25, steps per second: 204, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3184/100000: episode: 74, duration: 0.382s, episode steps:  76, steps per second: 199, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.355 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3210/100000: episode: 75, duration: 0.130s, episode steps:  26, steps per second: 200, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3235/100000: episode: 76, duration: 0.127s, episode steps:  25, steps per second: 197, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3314/100000: episode: 77, duration: 0.336s, episode steps:  79, steps per second: 235, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.241 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3339/100000: episode: 78, duration: 0.098s, episode steps:  25, steps per second: 256, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3394/100000: episode: 79, duration: 0.166s, episode steps:  55, steps per second: 330, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.436 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3420/100000: episode: 80, duration: 0.081s, episode steps:  26, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.962 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3449/100000: episode: 81, duration: 0.102s, episode steps:  29, steps per second: 286, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3475/100000: episode: 82, duration: 0.091s, episode steps:  26, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3502/100000: episode: 83, duration: 0.082s, episode steps:  27, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.037 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3527/100000: episode: 84, duration: 0.077s, episode steps:  25, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.080 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3554/100000: episode: 85, duration: 0.094s, episode steps:  27, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3582/100000: episode: 86, duration: 0.084s, episode steps:  28, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3607/100000: episode: 87, duration: 0.076s, episode steps:  25, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3632/100000: episode: 88, duration: 0.082s, episode steps:  25, steps per second: 305, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3664/100000: episode: 89, duration: 0.098s, episode steps:  32, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.531 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3720/100000: episode: 90, duration: 0.165s, episode steps:  56, steps per second: 339, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.286 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3748/100000: episode: 91, duration: 0.082s, episode steps:  28, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.429 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3776/100000: episode: 92, duration: 0.096s, episode steps:  28, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3802/100000: episode: 93, duration: 0.091s, episode steps:  26, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3829/100000: episode: 94, duration: 0.082s, episode steps:  27, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.926 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3856/100000: episode: 95, duration: 0.080s, episode steps:  27, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3884/100000: episode: 96, duration: 0.096s, episode steps:  28, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.071 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3909/100000: episode: 97, duration: 0.081s, episode steps:  25, steps per second: 308, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3935/100000: episode: 98, duration: 0.078s, episode steps:  26, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3960/100000: episode: 99, duration: 0.093s, episode steps:  25, steps per second: 269, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  3987/100000: episode: 100, duration: 0.082s, episode steps:  27, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4013/100000: episode: 101, duration: 0.079s, episode steps:  26, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4038/100000: episode: 102, duration: 0.089s, episode steps:  25, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4076/100000: episode: 103, duration: 0.108s, episode steps:  38, steps per second: 353, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.711 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4102/100000: episode: 104, duration: 0.095s, episode steps:  26, steps per second: 274, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4131/100000: episode: 105, duration: 0.098s, episode steps:  29, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4165/100000: episode: 106, duration: 0.101s, episode steps:  34, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.647 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4196/100000: episode: 107, duration: 0.092s, episode steps:  31, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.484 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4223/100000: episode: 108, duration: 0.095s, episode steps:  27, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4255/100000: episode: 109, duration: 0.091s, episode steps:  32, steps per second: 350, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.469 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4285/100000: episode: 110, duration: 0.085s, episode steps:  30, steps per second: 352, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.533 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4339/100000: episode: 111, duration: 0.166s, episode steps:  54, steps per second: 325, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.537 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4365/100000: episode: 112, duration: 0.078s, episode steps:  26, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4390/100000: episode: 113, duration: 0.078s, episode steps:  25, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.040 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4419/100000: episode: 114, duration: 0.097s, episode steps:  29, steps per second: 297, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4478/100000: episode: 115, duration: 0.175s, episode steps:  59, steps per second: 337, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.339 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4503/100000: episode: 116, duration: 0.085s, episode steps:  25, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4528/100000: episode: 117, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4553/100000: episode: 118, duration: 0.074s, episode steps:  25, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4580/100000: episode: 119, duration: 0.094s, episode steps:  27, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4663/100000: episode: 120, duration: 0.232s, episode steps:  83, steps per second: 358, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.506 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4690/100000: episode: 121, duration: 0.082s, episode steps:  27, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4717/100000: episode: 122, duration: 0.080s, episode steps:  27, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4743/100000: episode: 123, duration: 0.090s, episode steps:  26, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4768/100000: episode: 124, duration: 0.093s, episode steps:  25, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4793/100000: episode: 125, duration: 0.075s, episode steps:  25, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4818/100000: episode: 126, duration: 0.091s, episode steps:  25, steps per second: 274, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4849/100000: episode: 127, duration: 0.095s, episode steps:  31, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.355 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4875/100000: episode: 128, duration: 0.085s, episode steps:  26, steps per second: 305, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  4996/100000: episode: 129, duration: 0.331s, episode steps: 121, steps per second: 366, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.603 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5022/100000: episode: 130, duration: 0.075s, episode steps:  26, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5049/100000: episode: 131, duration: 0.083s, episode steps:  27, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5078/100000: episode: 132, duration: 0.097s, episode steps:  29, steps per second: 299, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.517 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5105/100000: episode: 133, duration: 0.098s, episode steps:  27, steps per second: 277, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5133/100000: episode: 134, duration: 0.088s, episode steps:  28, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.429 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5159/100000: episode: 135, duration: 0.091s, episode steps:  26, steps per second: 286, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5188/100000: episode: 136, duration: 0.089s, episode steps:  29, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.690 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5242/100000: episode: 137, duration: 0.162s, episode steps:  54, steps per second: 333, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5268/100000: episode: 138, duration: 0.077s, episode steps:  26, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5293/100000: episode: 139, duration: 0.077s, episode steps:  25, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5319/100000: episode: 140, duration: 0.088s, episode steps:  26, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.885 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5345/100000: episode: 141, duration: 0.082s, episode steps:  26, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5371/100000: episode: 142, duration: 0.103s, episode steps:  26, steps per second: 252, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5399/100000: episode: 143, duration: 0.104s, episode steps:  28, steps per second: 270, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5426/100000: episode: 144, duration: 0.094s, episode steps:  27, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5452/100000: episode: 145, duration: 0.081s, episode steps:  26, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5477/100000: episode: 146, duration: 0.086s, episode steps:  25, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5580/100000: episode: 147, duration: 0.280s, episode steps: 103, steps per second: 367, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.456 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5637/100000: episode: 148, duration: 0.156s, episode steps:  57, steps per second: 366, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.474 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5741/100000: episode: 149, duration: 0.284s, episode steps: 104, steps per second: 366, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.644 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5766/100000: episode: 150, duration: 0.103s, episode steps:  25, steps per second: 243, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.160 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5796/100000: episode: 151, duration: 0.114s, episode steps:  30, steps per second: 264, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.467 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5826/100000: episode: 152, duration: 0.104s, episode steps:  30, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.633 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5903/100000: episode: 153, duration: 0.214s, episode steps:  77, steps per second: 360, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5932/100000: episode: 154, duration: 0.086s, episode steps:  29, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.310 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5958/100000: episode: 155, duration: 0.078s, episode steps:  26, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  5984/100000: episode: 156, duration: 0.089s, episode steps:  26, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6016/100000: episode: 157, duration: 0.093s, episode steps:  32, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.312 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6074/100000: episode: 158, duration: 0.171s, episode steps:  58, steps per second: 339, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.603 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6099/100000: episode: 159, duration: 0.087s, episode steps:  25, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6125/100000: episode: 160, duration: 0.080s, episode steps:  26, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6156/100000: episode: 161, duration: 0.098s, episode steps:  31, steps per second: 315, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.323 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6183/100000: episode: 162, duration: 0.080s, episode steps:  27, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6208/100000: episode: 163, duration: 0.078s, episode steps:  25, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.120 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6237/100000: episode: 164, duration: 0.098s, episode steps:  29, steps per second: 297, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.276 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6272/100000: episode: 165, duration: 0.103s, episode steps:  35, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.286 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6297/100000: episode: 166, duration: 0.077s, episode steps:  25, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6352/100000: episode: 167, duration: 0.193s, episode steps:  55, steps per second: 285, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.782 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6378/100000: episode: 168, duration: 0.081s, episode steps:  26, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6403/100000: episode: 169, duration: 0.078s, episode steps:  25, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6433/100000: episode: 170, duration: 0.113s, episode steps:  30, steps per second: 265, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.833 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6458/100000: episode: 171, duration: 0.077s, episode steps:  25, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6559/100000: episode: 172, duration: 0.368s, episode steps: 101, steps per second: 275, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.406 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6635/100000: episode: 173, duration: 0.333s, episode steps:  76, steps per second: 228, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.684 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6663/100000: episode: 174, duration: 0.136s, episode steps:  28, steps per second: 205, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.750 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6719/100000: episode: 175, duration: 0.248s, episode steps:  56, steps per second: 226, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.304 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6759/100000: episode: 176, duration: 0.168s, episode steps:  40, steps per second: 238, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.725 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6786/100000: episode: 177, duration: 0.145s, episode steps:  27, steps per second: 186, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6857/100000: episode: 178, duration: 0.307s, episode steps:  71, steps per second: 231, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.549 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6889/100000: episode: 179, duration: 0.135s, episode steps:  32, steps per second: 237, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.531 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6914/100000: episode: 180, duration: 0.143s, episode steps:  25, steps per second: 174, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  6967/100000: episode: 181, duration: 0.247s, episode steps:  53, steps per second: 215, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.679 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7040/100000: episode: 182, duration: 0.322s, episode steps:  73, steps per second: 226, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.603 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7067/100000: episode: 183, duration: 0.130s, episode steps:  27, steps per second: 207, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7092/100000: episode: 184, duration: 0.125s, episode steps:  25, steps per second: 200, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.120 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7118/100000: episode: 185, duration: 0.122s, episode steps:  26, steps per second: 213, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7147/100000: episode: 186, duration: 0.160s, episode steps:  29, steps per second: 182, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.552 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7176/100000: episode: 187, duration: 0.138s, episode steps:  29, steps per second: 210, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.552 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7209/100000: episode: 188, duration: 0.158s, episode steps:  33, steps per second: 208, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.788 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7235/100000: episode: 189, duration: 0.119s, episode steps:  26, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7264/100000: episode: 190, duration: 0.135s, episode steps:  29, steps per second: 215, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.241 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7292/100000: episode: 191, duration: 0.130s, episode steps:  28, steps per second: 216, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.429 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7321/100000: episode: 192, duration: 0.087s, episode steps:  29, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.931 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7352/100000: episode: 193, duration: 0.107s, episode steps:  31, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.161 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7378/100000: episode: 194, duration: 0.081s, episode steps:  26, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7409/100000: episode: 195, duration: 0.105s, episode steps:  31, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.548 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7440/100000: episode: 196, duration: 0.107s, episode steps:  31, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.452 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7466/100000: episode: 197, duration: 0.078s, episode steps:  26, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7567/100000: episode: 198, duration: 0.276s, episode steps: 101, steps per second: 366, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.396 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7593/100000: episode: 199, duration: 0.080s, episode steps:  26, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.154 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7618/100000: episode: 200, duration: 0.078s, episode steps:  25, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7644/100000: episode: 201, duration: 0.094s, episode steps:  26, steps per second: 276, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7707/100000: episode: 202, duration: 0.175s, episode steps:  63, steps per second: 360, episode reward:  1.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.651 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7734/100000: episode: 203, duration: 0.101s, episode steps:  27, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.778 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7761/100000: episode: 204, duration: 0.085s, episode steps:  27, steps per second: 316, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7821/100000: episode: 205, duration: 0.182s, episode steps:  60, steps per second: 330, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.583 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7846/100000: episode: 206, duration: 0.076s, episode steps:  25, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7874/100000: episode: 207, duration: 0.085s, episode steps:  28, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  7929/100000: episode: 208, duration: 0.163s, episode steps:  55, steps per second: 338, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.218 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8003/100000: episode: 209, duration: 0.208s, episode steps:  74, steps per second: 356, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.338 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8061/100000: episode: 210, duration: 0.176s, episode steps:  58, steps per second: 329, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.534 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8089/100000: episode: 211, duration: 0.095s, episode steps:  28, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.071 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8117/100000: episode: 212, duration: 0.090s, episode steps:  28, steps per second: 311, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.214 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8144/100000: episode: 213, duration: 0.092s, episode steps:  27, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8171/100000: episode: 214, duration: 0.085s, episode steps:  27, steps per second: 316, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8250/100000: episode: 215, duration: 0.226s, episode steps:  79, steps per second: 349, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.418 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8275/100000: episode: 216, duration: 0.079s, episode steps:  25, steps per second: 318, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8309/100000: episode: 217, duration: 0.106s, episode steps:  34, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8337/100000: episode: 218, duration: 0.098s, episode steps:  28, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.714 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8371/100000: episode: 219, duration: 0.103s, episode steps:  34, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.529 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8444/100000: episode: 220, duration: 0.225s, episode steps:  73, steps per second: 324, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.726 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8469/100000: episode: 221, duration: 0.077s, episode steps:  25, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8494/100000: episode: 222, duration: 0.078s, episode steps:  25, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8522/100000: episode: 223, duration: 0.094s, episode steps:  28, steps per second: 299, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8547/100000: episode: 224, duration: 0.078s, episode steps:  25, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8580/100000: episode: 225, duration: 0.097s, episode steps:  33, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.424 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8686/100000: episode: 226, duration: 0.303s, episode steps: 106, steps per second: 350, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8757/100000: episode: 227, duration: 0.206s, episode steps:  71, steps per second: 344, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.437 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8866/100000: episode: 228, duration: 0.306s, episode steps: 109, steps per second: 356, episode reward:  2.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.394 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8893/100000: episode: 229, duration: 0.081s, episode steps:  27, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.185 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8922/100000: episode: 230, duration: 0.089s, episode steps:  29, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8948/100000: episode: 231, duration: 0.091s, episode steps:  26, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  8975/100000: episode: 232, duration: 0.084s, episode steps:  27, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9005/100000: episode: 233, duration: 0.089s, episode steps:  30, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.533 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9037/100000: episode: 234, duration: 0.107s, episode steps:  32, steps per second: 300, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9067/100000: episode: 235, duration: 0.090s, episode steps:  30, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9092/100000: episode: 236, duration: 0.093s, episode steps:  25, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.080 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9119/100000: episode: 237, duration: 0.101s, episode steps:  27, steps per second: 266, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9152/100000: episode: 238, duration: 0.101s, episode steps:  33, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.242 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9180/100000: episode: 239, duration: 0.098s, episode steps:  28, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.036 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9206/100000: episode: 240, duration: 0.106s, episode steps:  26, steps per second: 245, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9241/100000: episode: 241, duration: 0.120s, episode steps:  35, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9266/100000: episode: 242, duration: 0.081s, episode steps:  25, steps per second: 310, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9337/100000: episode: 243, duration: 0.223s, episode steps:  71, steps per second: 318, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.662 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9438/100000: episode: 244, duration: 0.340s, episode steps: 101, steps per second: 297, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.475 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9464/100000: episode: 245, duration: 0.082s, episode steps:  26, steps per second: 318, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9489/100000: episode: 246, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9568/100000: episode: 247, duration: 0.234s, episode steps:  79, steps per second: 338, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.684 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9595/100000: episode: 248, duration: 0.087s, episode steps:  27, steps per second: 311, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9620/100000: episode: 249, duration: 0.080s, episode steps:  25, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9722/100000: episode: 250, duration: 0.290s, episode steps: 102, steps per second: 352, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.343 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9831/100000: episode: 251, duration: 0.310s, episode steps: 109, steps per second: 352, episode reward:  2.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.495 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9861/100000: episode: 252, duration: 0.090s, episode steps:  30, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.467 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9893/100000: episode: 253, duration: 0.096s, episode steps:  32, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.406 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9918/100000: episode: 254, duration: 0.089s, episode steps:  25, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9945/100000: episode: 255, duration: 0.085s, episode steps:  27, steps per second: 318, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9972/100000: episode: 256, duration: 0.078s, episode steps:  27, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.148 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
  9997/100000: episode: 257, duration: 0.086s, episode steps:  25, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10032/100000: episode: 258, duration: 0.105s, episode steps:  35, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.657 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10058/100000: episode: 259, duration: 0.075s, episode steps:  26, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.308 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10084/100000: episode: 260, duration: 0.099s, episode steps:  26, steps per second: 262, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10118/100000: episode: 261, duration: 0.103s, episode steps:  34, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.176 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10153/100000: episode: 262, duration: 0.100s, episode steps:  35, steps per second: 350, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.686 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10212/100000: episode: 263, duration: 0.177s, episode steps:  59, steps per second: 333, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.373 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10245/100000: episode: 264, duration: 0.100s, episode steps:  33, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.515 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10333/100000: episode: 265, duration: 0.246s, episode steps:  88, steps per second: 357, episode reward:  2.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.602 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10369/100000: episode: 266, duration: 0.106s, episode steps:  36, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10394/100000: episode: 267, duration: 0.073s, episode steps:  25, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10419/100000: episode: 268, duration: 0.094s, episode steps:  25, steps per second: 266, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10449/100000: episode: 269, duration: 0.094s, episode steps:  30, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10478/100000: episode: 270, duration: 0.084s, episode steps:  29, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10505/100000: episode: 271, duration: 0.094s, episode steps:  27, steps per second: 286, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10539/100000: episode: 272, duration: 0.133s, episode steps:  34, steps per second: 255, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.529 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10611/100000: episode: 273, duration: 0.332s, episode steps:  72, steps per second: 217, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.417 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10636/100000: episode: 274, duration: 0.113s, episode steps:  25, steps per second: 221, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10661/100000: episode: 275, duration: 0.120s, episode steps:  25, steps per second: 208, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10687/100000: episode: 276, duration: 0.113s, episode steps:  26, steps per second: 229, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10788/100000: episode: 277, duration: 0.414s, episode steps: 101, steps per second: 244, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.406 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10819/100000: episode: 278, duration: 0.130s, episode steps:  31, steps per second: 239, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.484 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10844/100000: episode: 279, duration: 0.126s, episode steps:  25, steps per second: 199, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10876/100000: episode: 280, duration: 0.146s, episode steps:  32, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.781 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10908/100000: episode: 281, duration: 0.171s, episode steps:  32, steps per second: 187, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.219 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10939/100000: episode: 282, duration: 0.156s, episode steps:  31, steps per second: 198, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.097 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10966/100000: episode: 283, duration: 0.141s, episode steps:  27, steps per second: 192, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.037 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 10995/100000: episode: 284, duration: 0.144s, episode steps:  29, steps per second: 201, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.448 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11021/100000: episode: 285, duration: 0.138s, episode steps:  26, steps per second: 189, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11048/100000: episode: 286, duration: 0.113s, episode steps:  27, steps per second: 239, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11079/100000: episode: 287, duration: 0.144s, episode steps:  31, steps per second: 215, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.355 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11105/100000: episode: 288, duration: 0.117s, episode steps:  26, steps per second: 223, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11141/100000: episode: 289, duration: 0.177s, episode steps:  36, steps per second: 203, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11167/100000: episode: 290, duration: 0.120s, episode steps:  26, steps per second: 217, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11192/100000: episode: 291, duration: 0.128s, episode steps:  25, steps per second: 196, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11219/100000: episode: 292, duration: 0.122s, episode steps:  27, steps per second: 222, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11246/100000: episode: 293, duration: 0.136s, episode steps:  27, steps per second: 199, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11274/100000: episode: 294, duration: 0.138s, episode steps:  28, steps per second: 203, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.321 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11302/100000: episode: 295, duration: 0.128s, episode steps:  28, steps per second: 218, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.321 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11358/100000: episode: 296, duration: 0.155s, episode steps:  56, steps per second: 361, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.554 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11385/100000: episode: 297, duration: 0.106s, episode steps:  27, steps per second: 256, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11458/100000: episode: 298, duration: 0.196s, episode steps:  73, steps per second: 373, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.425 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11483/100000: episode: 299, duration: 0.092s, episode steps:  25, steps per second: 272, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11513/100000: episode: 300, duration: 0.091s, episode steps:  30, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.633 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11567/100000: episode: 301, duration: 0.162s, episode steps:  54, steps per second: 333, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11599/100000: episode: 302, duration: 0.093s, episode steps:  32, steps per second: 345, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.375 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11653/100000: episode: 303, duration: 0.157s, episode steps:  54, steps per second: 344, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11681/100000: episode: 304, duration: 0.088s, episode steps:  28, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.714 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11707/100000: episode: 305, duration: 0.074s, episode steps:  26, steps per second: 352, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.962 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11733/100000: episode: 306, duration: 0.102s, episode steps:  26, steps per second: 254, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.038 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11759/100000: episode: 307, duration: 0.076s, episode steps:  26, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11787/100000: episode: 308, duration: 0.082s, episode steps:  28, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.357 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11813/100000: episode: 309, duration: 0.096s, episode steps:  26, steps per second: 272, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11839/100000: episode: 310, duration: 0.082s, episode steps:  26, steps per second: 318, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11865/100000: episode: 311, duration: 0.087s, episode steps:  26, steps per second: 298, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11896/100000: episode: 312, duration: 0.102s, episode steps:  31, steps per second: 305, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.452 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11922/100000: episode: 313, duration: 0.076s, episode steps:  26, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.154 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11950/100000: episode: 314, duration: 0.083s, episode steps:  28, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.607 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 11979/100000: episode: 315, duration: 0.099s, episode steps:  29, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.207 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12007/100000: episode: 316, duration: 0.084s, episode steps:  28, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.607 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12033/100000: episode: 317, duration: 0.078s, episode steps:  26, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12086/100000: episode: 318, duration: 0.211s, episode steps:  53, steps per second: 251, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.434 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12113/100000: episode: 319, duration: 0.086s, episode steps:  27, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12140/100000: episode: 320, duration: 0.083s, episode steps:  27, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12168/100000: episode: 321, duration: 0.095s, episode steps:  28, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.607 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12196/100000: episode: 322, duration: 0.085s, episode steps:  28, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12271/100000: episode: 323, duration: 0.207s, episode steps:  75, steps per second: 362, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.573 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12296/100000: episode: 324, duration: 0.077s, episode steps:  25, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12327/100000: episode: 325, duration: 0.090s, episode steps:  31, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.258 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12352/100000: episode: 326, duration: 0.084s, episode steps:  25, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12377/100000: episode: 327, duration: 0.073s, episode steps:  25, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12405/100000: episode: 328, duration: 0.099s, episode steps:  28, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12430/100000: episode: 329, duration: 0.088s, episode steps:  25, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12455/100000: episode: 330, duration: 0.076s, episode steps:  25, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12508/100000: episode: 331, duration: 0.159s, episode steps:  53, steps per second: 333, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.472 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12671/100000: episode: 332, duration: 0.430s, episode steps: 163, steps per second: 379, episode reward:  3.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.313 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12701/100000: episode: 333, duration: 0.086s, episode steps:  30, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12726/100000: episode: 334, duration: 0.076s, episode steps:  25, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12753/100000: episode: 335, duration: 0.113s, episode steps:  27, steps per second: 240, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12832/100000: episode: 336, duration: 0.243s, episode steps:  79, steps per second: 326, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.557 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12858/100000: episode: 337, duration: 0.079s, episode steps:  26, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12883/100000: episode: 338, duration: 0.076s, episode steps:  25, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12962/100000: episode: 339, duration: 0.217s, episode steps:  79, steps per second: 364, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.380 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 12988/100000: episode: 340, duration: 0.078s, episode steps:  26, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13013/100000: episode: 341, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.040 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13042/100000: episode: 342, duration: 0.093s, episode steps:  29, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13068/100000: episode: 343, duration: 0.083s, episode steps:  26, steps per second: 313, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13117/100000: episode: 344, duration: 0.158s, episode steps:  49, steps per second: 309, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.735 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13146/100000: episode: 345, duration: 0.086s, episode steps:  29, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13218/100000: episode: 346, duration: 0.207s, episode steps:  72, steps per second: 347, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.319 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13246/100000: episode: 347, duration: 0.085s, episode steps:  28, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.464 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13272/100000: episode: 348, duration: 0.081s, episode steps:  26, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13297/100000: episode: 349, duration: 0.082s, episode steps:  25, steps per second: 304, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13325/100000: episode: 350, duration: 0.086s, episode steps:  28, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.036 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13397/100000: episode: 351, duration: 0.203s, episode steps:  72, steps per second: 354, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.597 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13422/100000: episode: 352, duration: 0.087s, episode steps:  25, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13447/100000: episode: 353, duration: 0.088s, episode steps:  25, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13474/100000: episode: 354, duration: 0.098s, episode steps:  27, steps per second: 275, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13506/100000: episode: 355, duration: 0.098s, episode steps:  32, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.594 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13533/100000: episode: 356, duration: 0.083s, episode steps:  27, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13564/100000: episode: 357, duration: 0.099s, episode steps:  31, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.581 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13623/100000: episode: 358, duration: 0.158s, episode steps:  59, steps per second: 373, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.610 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13649/100000: episode: 359, duration: 0.091s, episode steps:  26, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13683/100000: episode: 360, duration: 0.099s, episode steps:  34, steps per second: 345, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.647 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13712/100000: episode: 361, duration: 0.089s, episode steps:  29, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13737/100000: episode: 362, duration: 0.086s, episode steps:  25, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13764/100000: episode: 363, duration: 0.092s, episode steps:  27, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.111 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13797/100000: episode: 364, duration: 0.095s, episode steps:  33, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.879 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13824/100000: episode: 365, duration: 0.093s, episode steps:  27, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.778 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13849/100000: episode: 366, duration: 0.076s, episode steps:  25, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13874/100000: episode: 367, duration: 0.075s, episode steps:  25, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13933/100000: episode: 368, duration: 0.175s, episode steps:  59, steps per second: 337, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.780 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13960/100000: episode: 369, duration: 0.079s, episode steps:  27, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 13989/100000: episode: 370, duration: 0.083s, episode steps:  29, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14014/100000: episode: 371, duration: 0.087s, episode steps:  25, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14040/100000: episode: 372, duration: 0.079s, episode steps:  26, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14066/100000: episode: 373, duration: 0.082s, episode steps:  26, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.885 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14097/100000: episode: 374, duration: 0.115s, episode steps:  31, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.677 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14123/100000: episode: 375, duration: 0.079s, episode steps:  26, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14148/100000: episode: 376, duration: 0.080s, episode steps:  25, steps per second: 311, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14174/100000: episode: 377, duration: 0.088s, episode steps:  26, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14227/100000: episode: 378, duration: 0.144s, episode steps:  53, steps per second: 368, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.396 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14258/100000: episode: 379, duration: 0.101s, episode steps:  31, steps per second: 305, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.484 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14287/100000: episode: 380, duration: 0.089s, episode steps:  29, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.483 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14316/100000: episode: 381, duration: 0.111s, episode steps:  29, steps per second: 262, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.793 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14416/100000: episode: 382, duration: 0.277s, episode steps: 100, steps per second: 361, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14443/100000: episode: 383, duration: 0.097s, episode steps:  27, steps per second: 279, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14472/100000: episode: 384, duration: 0.092s, episode steps:  29, steps per second: 316, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.138 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14592/100000: episode: 385, duration: 0.415s, episode steps: 120, steps per second: 289, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.575 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14666/100000: episode: 386, duration: 0.328s, episode steps:  74, steps per second: 225, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.541 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14768/100000: episode: 387, duration: 0.422s, episode steps: 102, steps per second: 242, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14793/100000: episode: 388, duration: 0.117s, episode steps:  25, steps per second: 214, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14851/100000: episode: 389, duration: 0.258s, episode steps:  58, steps per second: 225, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.517 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14876/100000: episode: 390, duration: 0.118s, episode steps:  25, steps per second: 212, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14901/100000: episode: 391, duration: 0.133s, episode steps:  25, steps per second: 187, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 14926/100000: episode: 392, duration: 0.119s, episode steps:  25, steps per second: 210, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.880 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15000/100000: episode: 393, duration: 0.325s, episode steps:  74, steps per second: 227, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.514 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15028/100000: episode: 394, duration: 0.126s, episode steps:  28, steps per second: 223, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.321 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15058/100000: episode: 395, duration: 0.152s, episode steps:  30, steps per second: 198, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15085/100000: episode: 396, duration: 0.119s, episode steps:  27, steps per second: 226, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15110/100000: episode: 397, duration: 0.146s, episode steps:  25, steps per second: 171, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15135/100000: episode: 398, duration: 0.125s, episode steps:  25, steps per second: 200, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15207/100000: episode: 399, duration: 0.315s, episode steps:  72, steps per second: 229, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.542 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15232/100000: episode: 400, duration: 0.117s, episode steps:  25, steps per second: 215, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15258/100000: episode: 401, duration: 0.126s, episode steps:  26, steps per second: 206, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15283/100000: episode: 402, duration: 0.110s, episode steps:  25, steps per second: 228, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15312/100000: episode: 403, duration: 0.146s, episode steps:  29, steps per second: 199, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.414 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15367/100000: episode: 404, duration: 0.215s, episode steps:  55, steps per second: 256, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.345 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15441/100000: episode: 405, duration: 0.226s, episode steps:  74, steps per second: 327, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.662 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15469/100000: episode: 406, duration: 0.084s, episode steps:  28, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15497/100000: episode: 407, duration: 0.082s, episode steps:  28, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.679 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15523/100000: episode: 408, duration: 0.084s, episode steps:  26, steps per second: 311, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15554/100000: episode: 409, duration: 0.092s, episode steps:  31, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.548 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15609/100000: episode: 410, duration: 0.166s, episode steps:  55, steps per second: 332, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.364 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15636/100000: episode: 411, duration: 0.086s, episode steps:  27, steps per second: 313, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15665/100000: episode: 412, duration: 0.086s, episode steps:  29, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15697/100000: episode: 413, duration: 0.106s, episode steps:  32, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.562 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15723/100000: episode: 414, duration: 0.085s, episode steps:  26, steps per second: 307, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15757/100000: episode: 415, duration: 0.100s, episode steps:  34, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.441 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15784/100000: episode: 416, duration: 0.110s, episode steps:  27, steps per second: 246, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15870/100000: episode: 417, duration: 0.239s, episode steps:  86, steps per second: 360, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.395 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15898/100000: episode: 418, duration: 0.083s, episode steps:  28, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15955/100000: episode: 419, duration: 0.174s, episode steps:  57, steps per second: 327, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.596 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 15982/100000: episode: 420, duration: 0.079s, episode steps:  27, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16040/100000: episode: 421, duration: 0.175s, episode steps:  58, steps per second: 331, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.552 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16068/100000: episode: 422, duration: 0.083s, episode steps:  28, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.821 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16121/100000: episode: 423, duration: 0.164s, episode steps:  53, steps per second: 324, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.415 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16147/100000: episode: 424, duration: 0.077s, episode steps:  26, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16173/100000: episode: 425, duration: 0.080s, episode steps:  26, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16200/100000: episode: 426, duration: 0.093s, episode steps:  27, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.926 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16225/100000: episode: 427, duration: 0.076s, episode steps:  25, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.880 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16251/100000: episode: 428, duration: 0.080s, episode steps:  26, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16276/100000: episode: 429, duration: 0.094s, episode steps:  25, steps per second: 265, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16301/100000: episode: 430, duration: 0.074s, episode steps:  25, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16326/100000: episode: 431, duration: 0.077s, episode steps:  25, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16354/100000: episode: 432, duration: 0.108s, episode steps:  28, steps per second: 259, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.679 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16382/100000: episode: 433, duration: 0.084s, episode steps:  28, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16413/100000: episode: 434, duration: 0.092s, episode steps:  31, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.742 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16441/100000: episode: 435, duration: 0.106s, episode steps:  28, steps per second: 265, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.607 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16472/100000: episode: 436, duration: 0.091s, episode steps:  31, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.258 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16499/100000: episode: 437, duration: 0.081s, episode steps:  27, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16529/100000: episode: 438, duration: 0.095s, episode steps:  30, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.433 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16555/100000: episode: 439, duration: 0.077s, episode steps:  26, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16586/100000: episode: 440, duration: 0.093s, episode steps:  31, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.419 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16613/100000: episode: 441, duration: 0.093s, episode steps:  27, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16647/100000: episode: 442, duration: 0.099s, episode steps:  34, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.353 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16700/100000: episode: 443, duration: 0.156s, episode steps:  53, steps per second: 340, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.623 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16727/100000: episode: 444, duration: 0.077s, episode steps:  27, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16860/100000: episode: 445, duration: 0.364s, episode steps: 133, steps per second: 366, episode reward:  2.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.639 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16888/100000: episode: 446, duration: 0.081s, episode steps:  28, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.821 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16918/100000: episode: 447, duration: 0.087s, episode steps:  30, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.067 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16943/100000: episode: 448, duration: 0.088s, episode steps:  25, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16968/100000: episode: 449, duration: 0.080s, episode steps:  25, steps per second: 313, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 16994/100000: episode: 450, duration: 0.081s, episode steps:  26, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17024/100000: episode: 451, duration: 0.105s, episode steps:  30, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.533 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17050/100000: episode: 452, duration: 0.079s, episode steps:  26, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17082/100000: episode: 453, duration: 0.091s, episode steps:  32, steps per second: 352, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.562 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17109/100000: episode: 454, duration: 0.097s, episode steps:  27, steps per second: 278, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17182/100000: episode: 455, duration: 0.207s, episode steps:  73, steps per second: 352, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.397 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17236/100000: episode: 456, duration: 0.161s, episode steps:  54, steps per second: 336, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17265/100000: episode: 457, duration: 0.088s, episode steps:  29, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17342/100000: episode: 458, duration: 0.216s, episode steps:  77, steps per second: 356, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.364 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17367/100000: episode: 459, duration: 0.073s, episode steps:  25, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17445/100000: episode: 460, duration: 0.219s, episode steps:  78, steps per second: 356, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17548/100000: episode: 461, duration: 0.296s, episode steps: 103, steps per second: 348, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.524 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17576/100000: episode: 462, duration: 0.082s, episode steps:  28, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17602/100000: episode: 463, duration: 0.088s, episode steps:  26, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17627/100000: episode: 464, duration: 0.090s, episode steps:  25, steps per second: 279, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.120 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17727/100000: episode: 465, duration: 0.281s, episode steps: 100, steps per second: 356, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.570 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17753/100000: episode: 466, duration: 0.079s, episode steps:  26, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17888/100000: episode: 467, duration: 0.380s, episode steps: 135, steps per second: 356, episode reward:  2.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.363 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 17919/100000: episode: 468, duration: 0.088s, episode steps:  31, steps per second: 354, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.548 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18020/100000: episode: 469, duration: 0.282s, episode steps: 101, steps per second: 358, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.683 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18121/100000: episode: 470, duration: 0.279s, episode steps: 101, steps per second: 362, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.436 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18147/100000: episode: 471, duration: 0.077s, episode steps:  26, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.962 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18173/100000: episode: 472, duration: 0.079s, episode steps:  26, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18200/100000: episode: 473, duration: 0.103s, episode steps:  27, steps per second: 262, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18273/100000: episode: 474, duration: 0.252s, episode steps:  73, steps per second: 290, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.479 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18344/100000: episode: 475, duration: 0.196s, episode steps:  71, steps per second: 362, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.479 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18369/100000: episode: 476, duration: 0.089s, episode steps:  25, steps per second: 281, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18397/100000: episode: 477, duration: 0.081s, episode steps:  28, steps per second: 345, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.750 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18423/100000: episode: 478, duration: 0.079s, episode steps:  26, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18451/100000: episode: 479, duration: 0.098s, episode steps:  28, steps per second: 286, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.357 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18477/100000: episode: 480, duration: 0.078s, episode steps:  26, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18508/100000: episode: 481, duration: 0.089s, episode steps:  31, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.419 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18534/100000: episode: 482, duration: 0.107s, episode steps:  26, steps per second: 242, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18563/100000: episode: 483, duration: 0.084s, episode steps:  29, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.517 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18634/100000: episode: 484, duration: 0.210s, episode steps:  71, steps per second: 338, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.380 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18709/100000: episode: 485, duration: 0.328s, episode steps:  75, steps per second: 229, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18736/100000: episode: 486, duration: 0.124s, episode steps:  27, steps per second: 217, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.963 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18761/100000: episode: 487, duration: 0.110s, episode steps:  25, steps per second: 226, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18786/100000: episode: 488, duration: 0.119s, episode steps:  25, steps per second: 210, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18819/100000: episode: 489, duration: 0.175s, episode steps:  33, steps per second: 189, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.455 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18852/100000: episode: 490, duration: 0.153s, episode steps:  33, steps per second: 216, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.485 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18881/100000: episode: 491, duration: 0.142s, episode steps:  29, steps per second: 205, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18908/100000: episode: 492, duration: 0.114s, episode steps:  27, steps per second: 236, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 18965/100000: episode: 493, duration: 0.235s, episode steps:  57, steps per second: 243, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.526 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19021/100000: episode: 494, duration: 0.244s, episode steps:  56, steps per second: 229, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.464 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19048/100000: episode: 495, duration: 0.139s, episode steps:  27, steps per second: 195, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19134/100000: episode: 496, duration: 0.353s, episode steps:  86, steps per second: 243, episode reward:  2.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.337 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19160/100000: episode: 497, duration: 0.112s, episode steps:  26, steps per second: 232, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19214/100000: episode: 498, duration: 0.216s, episode steps:  54, steps per second: 250, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.426 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19239/100000: episode: 499, duration: 0.106s, episode steps:  25, steps per second: 236, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19265/100000: episode: 500, duration: 0.126s, episode steps:  26, steps per second: 207, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19291/100000: episode: 501, duration: 0.143s, episode steps:  26, steps per second: 181, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19316/100000: episode: 502, duration: 0.121s, episode steps:  25, steps per second: 206, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19344/100000: episode: 503, duration: 0.132s, episode steps:  28, steps per second: 212, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.750 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19370/100000: episode: 504, duration: 0.138s, episode steps:  26, steps per second: 189, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19449/100000: episode: 505, duration: 0.323s, episode steps:  79, steps per second: 244, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.532 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19478/100000: episode: 506, duration: 0.100s, episode steps:  29, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.862 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19511/100000: episode: 507, duration: 0.097s, episode steps:  33, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.394 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19537/100000: episode: 508, duration: 0.100s, episode steps:  26, steps per second: 259, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19591/100000: episode: 509, duration: 0.147s, episode steps:  54, steps per second: 366, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.463 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19619/100000: episode: 510, duration: 0.096s, episode steps:  28, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19647/100000: episode: 511, duration: 0.084s, episode steps:  28, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.536 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19683/100000: episode: 512, duration: 0.105s, episode steps:  36, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19712/100000: episode: 513, duration: 0.097s, episode steps:  29, steps per second: 298, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.966 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19744/100000: episode: 514, duration: 0.094s, episode steps:  32, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.344 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19769/100000: episode: 515, duration: 0.078s, episode steps:  25, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19794/100000: episode: 516, duration: 0.091s, episode steps:  25, steps per second: 274, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19824/100000: episode: 517, duration: 0.086s, episode steps:  30, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.467 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19850/100000: episode: 518, duration: 0.080s, episode steps:  26, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19888/100000: episode: 519, duration: 0.133s, episode steps:  38, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.658 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19913/100000: episode: 520, duration: 0.074s, episode steps:  25, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19942/100000: episode: 521, duration: 0.081s, episode steps:  29, steps per second: 358, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19968/100000: episode: 522, duration: 0.089s, episode steps:  26, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 19993/100000: episode: 523, duration: 0.077s, episode steps:  25, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20023/100000: episode: 524, duration: 0.106s, episode steps:  30, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20048/100000: episode: 525, duration: 0.084s, episode steps:  25, steps per second: 298, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20073/100000: episode: 526, duration: 0.076s, episode steps:  25, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.080 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20101/100000: episode: 527, duration: 0.080s, episode steps:  28, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20155/100000: episode: 528, duration: 0.158s, episode steps:  54, steps per second: 342, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.389 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20181/100000: episode: 529, duration: 0.079s, episode steps:  26, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.154 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20206/100000: episode: 530, duration: 0.088s, episode steps:  25, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20234/100000: episode: 531, duration: 0.095s, episode steps:  28, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.393 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20306/100000: episode: 532, duration: 0.193s, episode steps:  72, steps per second: 373, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.611 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20409/100000: episode: 533, duration: 0.276s, episode steps: 103, steps per second: 373, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.456 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20480/100000: episode: 534, duration: 0.186s, episode steps:  71, steps per second: 382, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.592 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20505/100000: episode: 535, duration: 0.088s, episode steps:  25, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20565/100000: episode: 536, duration: 0.172s, episode steps:  60, steps per second: 349, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.567 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20625/100000: episode: 537, duration: 0.173s, episode steps:  60, steps per second: 348, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20650/100000: episode: 538, duration: 0.074s, episode steps:  25, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20724/100000: episode: 539, duration: 0.204s, episode steps:  74, steps per second: 362, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.622 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20751/100000: episode: 540, duration: 0.079s, episode steps:  27, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20822/100000: episode: 541, duration: 0.202s, episode steps:  71, steps per second: 352, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.310 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20849/100000: episode: 542, duration: 0.083s, episode steps:  27, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20874/100000: episode: 543, duration: 0.078s, episode steps:  25, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20909/100000: episode: 544, duration: 0.119s, episode steps:  35, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20938/100000: episode: 545, duration: 0.091s, episode steps:  29, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 20965/100000: episode: 546, duration: 0.079s, episode steps:  27, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21023/100000: episode: 547, duration: 0.165s, episode steps:  58, steps per second: 352, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21080/100000: episode: 548, duration: 0.153s, episode steps:  57, steps per second: 372, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.456 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21105/100000: episode: 549, duration: 0.089s, episode steps:  25, steps per second: 279, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21132/100000: episode: 550, duration: 0.078s, episode steps:  27, steps per second: 345, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21158/100000: episode: 551, duration: 0.084s, episode steps:  26, steps per second: 309, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.962 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21212/100000: episode: 552, duration: 0.167s, episode steps:  54, steps per second: 323, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.648 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21238/100000: episode: 553, duration: 0.101s, episode steps:  26, steps per second: 259, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21269/100000: episode: 554, duration: 0.121s, episode steps:  31, steps per second: 256, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.419 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21298/100000: episode: 555, duration: 0.095s, episode steps:  29, steps per second: 304, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.138 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21323/100000: episode: 556, duration: 0.077s, episode steps:  25, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21377/100000: episode: 557, duration: 0.158s, episode steps:  54, steps per second: 342, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21406/100000: episode: 558, duration: 0.084s, episode steps:  29, steps per second: 345, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21435/100000: episode: 559, duration: 0.083s, episode steps:  29, steps per second: 351, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.414 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21488/100000: episode: 560, duration: 0.155s, episode steps:  53, steps per second: 343, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.642 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21514/100000: episode: 561, duration: 0.082s, episode steps:  26, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21546/100000: episode: 562, duration: 0.094s, episode steps:  32, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.438 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21622/100000: episode: 563, duration: 0.229s, episode steps:  76, steps per second: 331, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.553 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21697/100000: episode: 564, duration: 0.199s, episode steps:  75, steps per second: 376, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21750/100000: episode: 565, duration: 0.155s, episode steps:  53, steps per second: 341, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.792 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21808/100000: episode: 566, duration: 0.160s, episode steps:  58, steps per second: 363, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.138 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21833/100000: episode: 567, duration: 0.091s, episode steps:  25, steps per second: 275, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21859/100000: episode: 568, duration: 0.081s, episode steps:  26, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21884/100000: episode: 569, duration: 0.080s, episode steps:  25, steps per second: 313, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 21985/100000: episode: 570, duration: 0.292s, episode steps: 101, steps per second: 346, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.465 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22012/100000: episode: 571, duration: 0.081s, episode steps:  27, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22093/100000: episode: 572, duration: 0.227s, episode steps:  81, steps per second: 357, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22165/100000: episode: 573, duration: 0.194s, episode steps:  72, steps per second: 372, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.583 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22192/100000: episode: 574, duration: 0.089s, episode steps:  27, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22223/100000: episode: 575, duration: 0.092s, episode steps:  31, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.484 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22248/100000: episode: 576, duration: 0.074s, episode steps:  25, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22276/100000: episode: 577, duration: 0.097s, episode steps:  28, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.750 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22301/100000: episode: 578, duration: 0.086s, episode steps:  25, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22326/100000: episode: 579, duration: 0.076s, episode steps:  25, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22389/100000: episode: 580, duration: 0.180s, episode steps:  63, steps per second: 349, episode reward:  1.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.317 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22466/100000: episode: 581, duration: 0.200s, episode steps:  77, steps per second: 385, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.494 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22493/100000: episode: 582, duration: 0.091s, episode steps:  27, steps per second: 298, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22567/100000: episode: 583, duration: 0.201s, episode steps:  74, steps per second: 368, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.527 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22592/100000: episode: 584, duration: 0.087s, episode steps:  25, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22617/100000: episode: 585, duration: 0.074s, episode steps:  25, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22642/100000: episode: 586, duration: 0.094s, episode steps:  25, steps per second: 265, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22667/100000: episode: 587, duration: 0.101s, episode steps:  25, steps per second: 248, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22692/100000: episode: 588, duration: 0.079s, episode steps:  25, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22721/100000: episode: 589, duration: 0.086s, episode steps:  29, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.034 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22749/100000: episode: 590, duration: 0.097s, episode steps:  28, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.464 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22776/100000: episode: 591, duration: 0.103s, episode steps:  27, steps per second: 263, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22801/100000: episode: 592, duration: 0.138s, episode steps:  25, steps per second: 182, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.880 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22878/100000: episode: 593, duration: 0.320s, episode steps:  77, steps per second: 241, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22906/100000: episode: 594, duration: 0.134s, episode steps:  28, steps per second: 208, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.393 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22935/100000: episode: 595, duration: 0.143s, episode steps:  29, steps per second: 203, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.345 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 22961/100000: episode: 596, duration: 0.119s, episode steps:  26, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23019/100000: episode: 597, duration: 0.229s, episode steps:  58, steps per second: 254, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.328 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23052/100000: episode: 598, duration: 0.146s, episode steps:  33, steps per second: 226, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.212 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23126/100000: episode: 599, duration: 0.304s, episode steps:  74, steps per second: 243, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.419 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23153/100000: episode: 600, duration: 0.122s, episode steps:  27, steps per second: 222, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23180/100000: episode: 601, duration: 0.129s, episode steps:  27, steps per second: 210, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23213/100000: episode: 602, duration: 0.166s, episode steps:  33, steps per second: 199, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.758 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23242/100000: episode: 603, duration: 0.145s, episode steps:  29, steps per second: 200, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.483 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23267/100000: episode: 604, duration: 0.137s, episode steps:  25, steps per second: 183, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.880 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23301/100000: episode: 605, duration: 0.163s, episode steps:  34, steps per second: 209, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.441 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23334/100000: episode: 606, duration: 0.154s, episode steps:  33, steps per second: 214, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.152 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23362/100000: episode: 607, duration: 0.143s, episode steps:  28, steps per second: 196, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.536 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23388/100000: episode: 608, duration: 0.129s, episode steps:  26, steps per second: 202, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23461/100000: episode: 609, duration: 0.308s, episode steps:  73, steps per second: 237, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.466 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23486/100000: episode: 610, duration: 0.133s, episode steps:  25, steps per second: 188, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23512/100000: episode: 611, duration: 0.141s, episode steps:  26, steps per second: 184, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23543/100000: episode: 612, duration: 0.147s, episode steps:  31, steps per second: 211, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.258 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23585/100000: episode: 613, duration: 0.158s, episode steps:  42, steps per second: 265, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23617/100000: episode: 614, duration: 0.105s, episode steps:  32, steps per second: 304, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23643/100000: episode: 615, duration: 0.077s, episode steps:  26, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.308 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23701/100000: episode: 616, duration: 0.168s, episode steps:  58, steps per second: 345, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23726/100000: episode: 617, duration: 0.078s, episode steps:  25, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23759/100000: episode: 618, duration: 0.098s, episode steps:  33, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.727 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23784/100000: episode: 619, duration: 0.089s, episode steps:  25, steps per second: 281, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23810/100000: episode: 620, duration: 0.079s, episode steps:  26, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23835/100000: episode: 621, duration: 0.072s, episode steps:  25, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23861/100000: episode: 622, duration: 0.084s, episode steps:  26, steps per second: 308, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23945/100000: episode: 623, duration: 0.226s, episode steps:  84, steps per second: 372, episode reward:  2.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 23970/100000: episode: 624, duration: 0.094s, episode steps:  25, steps per second: 266, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24041/100000: episode: 625, duration: 0.197s, episode steps:  71, steps per second: 360, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.549 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24067/100000: episode: 626, duration: 0.082s, episode steps:  26, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24092/100000: episode: 627, duration: 0.083s, episode steps:  25, steps per second: 300, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24118/100000: episode: 628, duration: 0.110s, episode steps:  26, steps per second: 236, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24146/100000: episode: 629, duration: 0.085s, episode steps:  28, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.357 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24171/100000: episode: 630, duration: 0.079s, episode steps:  25, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24196/100000: episode: 631, duration: 0.084s, episode steps:  25, steps per second: 296, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24228/100000: episode: 632, duration: 0.094s, episode steps:  32, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.625 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24328/100000: episode: 633, duration: 0.283s, episode steps: 100, steps per second: 353, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24355/100000: episode: 634, duration: 0.082s, episode steps:  27, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.963 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24428/100000: episode: 635, duration: 0.208s, episode steps:  73, steps per second: 351, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.411 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24453/100000: episode: 636, duration: 0.075s, episode steps:  25, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24577/100000: episode: 637, duration: 0.335s, episode steps: 124, steps per second: 370, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.637 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24654/100000: episode: 638, duration: 0.210s, episode steps:  77, steps per second: 366, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.390 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24681/100000: episode: 639, duration: 0.105s, episode steps:  27, steps per second: 257, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24752/100000: episode: 640, duration: 0.206s, episode steps:  71, steps per second: 344, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24777/100000: episode: 641, duration: 0.078s, episode steps:  25, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.960 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24831/100000: episode: 642, duration: 0.164s, episode steps:  54, steps per second: 329, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24864/100000: episode: 643, duration: 0.095s, episode steps:  33, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.909 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24901/100000: episode: 644, duration: 0.103s, episode steps:  37, steps per second: 361, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.595 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24928/100000: episode: 645, duration: 0.093s, episode steps:  27, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24955/100000: episode: 646, duration: 0.082s, episode steps:  27, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 24982/100000: episode: 647, duration: 0.082s, episode steps:  27, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25009/100000: episode: 648, duration: 0.101s, episode steps:  27, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.926 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25081/100000: episode: 649, duration: 0.191s, episode steps:  72, steps per second: 377, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.347 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25134/100000: episode: 650, duration: 0.159s, episode steps:  53, steps per second: 334, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.547 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25190/100000: episode: 651, duration: 0.151s, episode steps:  56, steps per second: 370, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.554 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25290/100000: episode: 652, duration: 0.278s, episode steps: 100, steps per second: 360, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.550 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25315/100000: episode: 653, duration: 0.079s, episode steps:  25, steps per second: 316, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25344/100000: episode: 654, duration: 0.088s, episode steps:  29, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.690 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25370/100000: episode: 655, duration: 0.103s, episode steps:  26, steps per second: 252, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25425/100000: episode: 656, duration: 0.155s, episode steps:  55, steps per second: 355, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.727 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25450/100000: episode: 657, duration: 0.088s, episode steps:  25, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25481/100000: episode: 658, duration: 0.093s, episode steps:  31, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.613 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25510/100000: episode: 659, duration: 0.088s, episode steps:  29, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.241 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25536/100000: episode: 660, duration: 0.088s, episode steps:  26, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25562/100000: episode: 661, duration: 0.081s, episode steps:  26, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25591/100000: episode: 662, duration: 0.100s, episode steps:  29, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25645/100000: episode: 663, duration: 0.163s, episode steps:  54, steps per second: 330, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.537 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25670/100000: episode: 664, duration: 0.074s, episode steps:  25, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.040 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25695/100000: episode: 665, duration: 0.091s, episode steps:  25, steps per second: 274, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.880 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25748/100000: episode: 666, duration: 0.157s, episode steps:  53, steps per second: 337, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.208 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25779/100000: episode: 667, duration: 0.095s, episode steps:  31, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.742 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25809/100000: episode: 668, duration: 0.091s, episode steps:  30, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.533 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25838/100000: episode: 669, duration: 0.097s, episode steps:  29, steps per second: 300, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.069 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25864/100000: episode: 670, duration: 0.079s, episode steps:  26, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25891/100000: episode: 671, duration: 0.081s, episode steps:  27, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25916/100000: episode: 672, duration: 0.085s, episode steps:  25, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25948/100000: episode: 673, duration: 0.089s, episode steps:  32, steps per second: 361, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.812 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 25976/100000: episode: 674, duration: 0.080s, episode steps:  28, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.607 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26005/100000: episode: 675, duration: 0.098s, episode steps:  29, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.172 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26033/100000: episode: 676, duration: 0.097s, episode steps:  28, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.821 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26060/100000: episode: 677, duration: 0.084s, episode steps:  27, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26086/100000: episode: 678, duration: 0.089s, episode steps:  26, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26168/100000: episode: 679, duration: 0.235s, episode steps:  82, steps per second: 349, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.402 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26199/100000: episode: 680, duration: 0.093s, episode steps:  31, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.774 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26237/100000: episode: 681, duration: 0.109s, episode steps:  38, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.447 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26272/100000: episode: 682, duration: 0.108s, episode steps:  35, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.229 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26298/100000: episode: 683, duration: 0.077s, episode steps:  26, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26326/100000: episode: 684, duration: 0.096s, episode steps:  28, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.321 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26354/100000: episode: 685, duration: 0.094s, episode steps:  28, steps per second: 297, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26384/100000: episode: 686, duration: 0.089s, episode steps:  30, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.433 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26409/100000: episode: 687, duration: 0.091s, episode steps:  25, steps per second: 275, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26434/100000: episode: 688, duration: 0.077s, episode steps:  25, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26514/100000: episode: 689, duration: 0.226s, episode steps:  80, steps per second: 354, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.475 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26540/100000: episode: 690, duration: 0.080s, episode steps:  26, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26569/100000: episode: 691, duration: 0.085s, episode steps:  29, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.207 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26623/100000: episode: 692, duration: 0.158s, episode steps:  54, steps per second: 342, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.426 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26649/100000: episode: 693, duration: 0.075s, episode steps:  26, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26682/100000: episode: 694, duration: 0.098s, episode steps:  33, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.545 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26707/100000: episode: 695, duration: 0.101s, episode steps:  25, steps per second: 247, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26733/100000: episode: 696, duration: 0.081s, episode steps:  26, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26761/100000: episode: 697, duration: 0.086s, episode steps:  28, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.214 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26790/100000: episode: 698, duration: 0.093s, episode steps:  29, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.345 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26815/100000: episode: 699, duration: 0.076s, episode steps:  25, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26840/100000: episode: 700, duration: 0.074s, episode steps:  25, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26867/100000: episode: 701, duration: 0.135s, episode steps:  27, steps per second: 200, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.963 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26899/100000: episode: 702, duration: 0.149s, episode steps:  32, steps per second: 214, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.562 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 26925/100000: episode: 703, duration: 0.142s, episode steps:  26, steps per second: 183, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27027/100000: episode: 704, duration: 0.433s, episode steps: 102, steps per second: 236, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.529 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27056/100000: episode: 705, duration: 0.133s, episode steps:  29, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27132/100000: episode: 706, duration: 0.326s, episode steps:  76, steps per second: 233, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.329 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27164/100000: episode: 707, duration: 0.149s, episode steps:  32, steps per second: 214, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.688 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27191/100000: episode: 708, duration: 0.139s, episode steps:  27, steps per second: 195, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.778 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27216/100000: episode: 709, duration: 0.131s, episode steps:  25, steps per second: 191, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27242/100000: episode: 710, duration: 0.131s, episode steps:  26, steps per second: 199, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27267/100000: episode: 711, duration: 0.118s, episode steps:  25, steps per second: 211, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27294/100000: episode: 712, duration: 0.135s, episode steps:  27, steps per second: 200, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27349/100000: episode: 713, duration: 0.247s, episode steps:  55, steps per second: 223, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.382 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27375/100000: episode: 714, duration: 0.116s, episode steps:  26, steps per second: 224, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27530/100000: episode: 715, duration: 0.613s, episode steps: 155, steps per second: 253, episode reward:  4.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.606 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27555/100000: episode: 716, duration: 0.116s, episode steps:  25, steps per second: 216, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27580/100000: episode: 717, duration: 0.113s, episode steps:  25, steps per second: 221, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27635/100000: episode: 718, duration: 0.254s, episode steps:  55, steps per second: 216, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.582 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27662/100000: episode: 719, duration: 0.141s, episode steps:  27, steps per second: 191, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27687/100000: episode: 720, duration: 0.109s, episode steps:  25, steps per second: 230, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.960 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27740/100000: episode: 721, duration: 0.144s, episode steps:  53, steps per second: 368, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.528 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27812/100000: episode: 722, duration: 0.204s, episode steps:  72, steps per second: 353, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.708 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27845/100000: episode: 723, duration: 0.095s, episode steps:  33, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.848 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27871/100000: episode: 724, duration: 0.076s, episode steps:  26, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27898/100000: episode: 725, duration: 0.096s, episode steps:  27, steps per second: 281, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 27969/100000: episode: 726, duration: 0.193s, episode steps:  71, steps per second: 368, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.437 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28040/100000: episode: 727, duration: 0.218s, episode steps:  71, steps per second: 326, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.465 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28165/100000: episode: 728, duration: 0.335s, episode steps: 125, steps per second: 373, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.632 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28242/100000: episode: 729, duration: 0.206s, episode steps:  77, steps per second: 374, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.455 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28267/100000: episode: 730, duration: 0.093s, episode steps:  25, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28300/100000: episode: 731, duration: 0.098s, episode steps:  33, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.545 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28325/100000: episode: 732, duration: 0.076s, episode steps:  25, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28350/100000: episode: 733, duration: 0.089s, episode steps:  25, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28379/100000: episode: 734, duration: 0.096s, episode steps:  29, steps per second: 302, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28404/100000: episode: 735, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.960 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28460/100000: episode: 736, duration: 0.170s, episode steps:  56, steps per second: 329, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28490/100000: episode: 737, duration: 0.096s, episode steps:  30, steps per second: 313, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.933 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28515/100000: episode: 738, duration: 0.082s, episode steps:  25, steps per second: 306, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28546/100000: episode: 739, duration: 0.107s, episode steps:  31, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.645 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28574/100000: episode: 740, duration: 0.086s, episode steps:  28, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.393 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28599/100000: episode: 741, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28624/100000: episode: 742, duration: 0.090s, episode steps:  25, steps per second: 278, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28649/100000: episode: 743, duration: 0.080s, episode steps:  25, steps per second: 313, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28676/100000: episode: 744, duration: 0.083s, episode steps:  27, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28780/100000: episode: 745, duration: 0.304s, episode steps: 104, steps per second: 342, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.606 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28806/100000: episode: 746, duration: 0.078s, episode steps:  26, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.885 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28831/100000: episode: 747, duration: 0.076s, episode steps:  25, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28858/100000: episode: 748, duration: 0.093s, episode steps:  27, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28961/100000: episode: 749, duration: 0.289s, episode steps: 103, steps per second: 356, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.592 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 28993/100000: episode: 750, duration: 0.093s, episode steps:  32, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.562 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29019/100000: episode: 751, duration: 0.078s, episode steps:  26, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.154 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29044/100000: episode: 752, duration: 0.085s, episode steps:  25, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29088/100000: episode: 753, duration: 0.141s, episode steps:  44, steps per second: 311, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.432 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29121/100000: episode: 754, duration: 0.109s, episode steps:  33, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29146/100000: episode: 755, duration: 0.078s, episode steps:  25, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29220/100000: episode: 756, duration: 0.211s, episode steps:  74, steps per second: 351, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.514 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29246/100000: episode: 757, duration: 0.081s, episode steps:  26, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29317/100000: episode: 758, duration: 0.214s, episode steps:  71, steps per second: 332, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.479 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29347/100000: episode: 759, duration: 0.088s, episode steps:  30, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.300 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29373/100000: episode: 760, duration: 0.077s, episode steps:  26, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29403/100000: episode: 761, duration: 0.116s, episode steps:  30, steps per second: 259, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.233 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29430/100000: episode: 762, duration: 0.084s, episode steps:  27, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29456/100000: episode: 763, duration: 0.081s, episode steps:  26, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29481/100000: episode: 764, duration: 0.084s, episode steps:  25, steps per second: 297, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29506/100000: episode: 765, duration: 0.073s, episode steps:  25, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29559/100000: episode: 766, duration: 0.157s, episode steps:  53, steps per second: 338, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.585 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29586/100000: episode: 767, duration: 0.089s, episode steps:  27, steps per second: 304, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29614/100000: episode: 768, duration: 0.087s, episode steps:  28, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.071 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29639/100000: episode: 769, duration: 0.089s, episode steps:  25, steps per second: 280, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29664/100000: episode: 770, duration: 0.076s, episode steps:  25, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29689/100000: episode: 771, duration: 0.073s, episode steps:  25, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29714/100000: episode: 772, duration: 0.089s, episode steps:  25, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29740/100000: episode: 773, duration: 0.094s, episode steps:  26, steps per second: 276, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29772/100000: episode: 774, duration: 0.096s, episode steps:  32, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.719 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29798/100000: episode: 775, duration: 0.090s, episode steps:  26, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29826/100000: episode: 776, duration: 0.086s, episode steps:  28, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.179 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29902/100000: episode: 777, duration: 0.219s, episode steps:  76, steps per second: 346, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.447 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29932/100000: episode: 778, duration: 0.088s, episode steps:  30, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.633 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29959/100000: episode: 779, duration: 0.085s, episode steps:  27, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 29989/100000: episode: 780, duration: 0.102s, episode steps:  30, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.567 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30014/100000: episode: 781, duration: 0.089s, episode steps:  25, steps per second: 281, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30040/100000: episode: 782, duration: 0.076s, episode steps:  26, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.885 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30065/100000: episode: 783, duration: 0.098s, episode steps:  25, steps per second: 256, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30098/100000: episode: 784, duration: 0.093s, episode steps:  33, steps per second: 356, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.636 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30170/100000: episode: 785, duration: 0.205s, episode steps:  72, steps per second: 351, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.611 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30199/100000: episode: 786, duration: 0.086s, episode steps:  29, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.724 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30253/100000: episode: 787, duration: 0.161s, episode steps:  54, steps per second: 335, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.648 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30282/100000: episode: 788, duration: 0.087s, episode steps:  29, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.276 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30337/100000: episode: 789, duration: 0.175s, episode steps:  55, steps per second: 314, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.582 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30363/100000: episode: 790, duration: 0.093s, episode steps:  26, steps per second: 281, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30403/100000: episode: 791, duration: 0.141s, episode steps:  40, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.425 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30456/100000: episode: 792, duration: 0.146s, episode steps:  53, steps per second: 363, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.509 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30481/100000: episode: 793, duration: 0.078s, episode steps:  25, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30510/100000: episode: 794, duration: 0.094s, episode steps:  29, steps per second: 307, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.897 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30536/100000: episode: 795, duration: 0.082s, episode steps:  26, steps per second: 318, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30563/100000: episode: 796, duration: 0.092s, episode steps:  27, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.222 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30638/100000: episode: 797, duration: 0.209s, episode steps:  75, steps per second: 359, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.507 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30830/100000: episode: 798, duration: 0.511s, episode steps: 192, steps per second: 376, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.380 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30890/100000: episode: 799, duration: 0.171s, episode steps:  60, steps per second: 351, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 30927/100000: episode: 800, duration: 0.122s, episode steps:  37, steps per second: 304, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.378 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31049/100000: episode: 801, duration: 0.466s, episode steps: 122, steps per second: 262, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.328 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31074/100000: episode: 802, duration: 0.134s, episode steps:  25, steps per second: 187, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31104/100000: episode: 803, duration: 0.152s, episode steps:  30, steps per second: 198, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31134/100000: episode: 804, duration: 0.145s, episode steps:  30, steps per second: 207, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31160/100000: episode: 805, duration: 0.133s, episode steps:  26, steps per second: 195, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31186/100000: episode: 806, duration: 0.119s, episode steps:  26, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31211/100000: episode: 807, duration: 0.143s, episode steps:  25, steps per second: 175, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31241/100000: episode: 808, duration: 0.131s, episode steps:  30, steps per second: 228, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.367 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31272/100000: episode: 809, duration: 0.139s, episode steps:  31, steps per second: 223, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.387 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31299/100000: episode: 810, duration: 0.130s, episode steps:  27, steps per second: 207, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.889 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31324/100000: episode: 811, duration: 0.137s, episode steps:  25, steps per second: 182, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31351/100000: episode: 812, duration: 0.128s, episode steps:  27, steps per second: 212, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31452/100000: episode: 813, duration: 0.411s, episode steps: 101, steps per second: 246, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.554 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31478/100000: episode: 814, duration: 0.112s, episode steps:  26, steps per second: 232, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31514/100000: episode: 815, duration: 0.158s, episode steps:  36, steps per second: 227, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.528 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31635/100000: episode: 816, duration: 0.513s, episode steps: 121, steps per second: 236, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.545 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31660/100000: episode: 817, duration: 0.118s, episode steps:  25, steps per second: 212, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.880 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31686/100000: episode: 818, duration: 0.129s, episode steps:  26, steps per second: 202, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31723/100000: episode: 819, duration: 0.176s, episode steps:  37, steps per second: 210, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.541 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31751/100000: episode: 820, duration: 0.148s, episode steps:  28, steps per second: 190, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.393 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31784/100000: episode: 821, duration: 0.105s, episode steps:  33, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.394 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31855/100000: episode: 822, duration: 0.210s, episode steps:  71, steps per second: 339, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.535 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31882/100000: episode: 823, duration: 0.083s, episode steps:  27, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31907/100000: episode: 824, duration: 0.075s, episode steps:  25, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31932/100000: episode: 825, duration: 0.088s, episode steps:  25, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31958/100000: episode: 826, duration: 0.082s, episode steps:  26, steps per second: 318, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 31985/100000: episode: 827, duration: 0.083s, episode steps:  27, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32011/100000: episode: 828, duration: 0.092s, episode steps:  26, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32037/100000: episode: 829, duration: 0.079s, episode steps:  26, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32062/100000: episode: 830, duration: 0.088s, episode steps:  25, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32087/100000: episode: 831, duration: 0.116s, episode steps:  25, steps per second: 215, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32112/100000: episode: 832, duration: 0.077s, episode steps:  25, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32195/100000: episode: 833, duration: 0.240s, episode steps:  83, steps per second: 346, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.482 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32220/100000: episode: 834, duration: 0.076s, episode steps:  25, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32245/100000: episode: 835, duration: 0.076s, episode steps:  25, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32303/100000: episode: 836, duration: 0.167s, episode steps:  58, steps per second: 347, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.638 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32329/100000: episode: 837, duration: 0.077s, episode steps:  26, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32355/100000: episode: 838, duration: 0.087s, episode steps:  26, steps per second: 299, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.692 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32431/100000: episode: 839, duration: 0.224s, episode steps:  76, steps per second: 339, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.474 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32457/100000: episode: 840, duration: 0.080s, episode steps:  26, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32485/100000: episode: 841, duration: 0.085s, episode steps:  28, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32513/100000: episode: 842, duration: 0.095s, episode steps:  28, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.464 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32539/100000: episode: 843, duration: 0.077s, episode steps:  26, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.231 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32639/100000: episode: 844, duration: 0.273s, episode steps: 100, steps per second: 366, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32665/100000: episode: 845, duration: 0.078s, episode steps:  26, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32773/100000: episode: 846, duration: 0.296s, episode steps: 108, steps per second: 365, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.611 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32799/100000: episode: 847, duration: 0.094s, episode steps:  26, steps per second: 277, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32824/100000: episode: 848, duration: 0.081s, episode steps:  25, steps per second: 310, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.120 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32853/100000: episode: 849, duration: 0.101s, episode steps:  29, steps per second: 286, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.724 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32880/100000: episode: 850, duration: 0.083s, episode steps:  27, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32905/100000: episode: 851, duration: 0.074s, episode steps:  25, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32931/100000: episode: 852, duration: 0.090s, episode steps:  26, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32961/100000: episode: 853, duration: 0.088s, episode steps:  30, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.267 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 32988/100000: episode: 854, duration: 0.084s, episode steps:  27, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33014/100000: episode: 855, duration: 0.094s, episode steps:  26, steps per second: 277, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33044/100000: episode: 856, duration: 0.091s, episode steps:  30, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.100 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33070/100000: episode: 857, duration: 0.076s, episode steps:  26, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33126/100000: episode: 858, duration: 0.176s, episode steps:  56, steps per second: 318, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33203/100000: episode: 859, duration: 0.211s, episode steps:  77, steps per second: 365, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33228/100000: episode: 860, duration: 0.086s, episode steps:  25, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33257/100000: episode: 861, duration: 0.087s, episode steps:  29, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.966 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33412/100000: episode: 862, duration: 0.444s, episode steps: 155, steps per second: 349, episode reward:  3.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.484 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33438/100000: episode: 863, duration: 0.080s, episode steps:  26, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33463/100000: episode: 864, duration: 0.090s, episode steps:  25, steps per second: 277, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33490/100000: episode: 865, duration: 0.095s, episode steps:  27, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33515/100000: episode: 866, duration: 0.079s, episode steps:  25, steps per second: 316, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33540/100000: episode: 867, duration: 0.074s, episode steps:  25, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33567/100000: episode: 868, duration: 0.088s, episode steps:  27, steps per second: 307, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33623/100000: episode: 869, duration: 0.152s, episode steps:  56, steps per second: 369, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.446 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33652/100000: episode: 870, duration: 0.094s, episode steps:  29, steps per second: 307, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.690 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33683/100000: episode: 871, duration: 0.093s, episode steps:  31, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.645 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33710/100000: episode: 872, duration: 0.081s, episode steps:  27, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33738/100000: episode: 873, duration: 0.091s, episode steps:  28, steps per second: 307, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.357 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33768/100000: episode: 874, duration: 0.090s, episode steps:  30, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33800/100000: episode: 875, duration: 0.109s, episode steps:  32, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33828/100000: episode: 876, duration: 0.095s, episode steps:  28, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.893 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33857/100000: episode: 877, duration: 0.083s, episode steps:  29, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33887/100000: episode: 878, duration: 0.087s, episode steps:  30, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.767 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33915/100000: episode: 879, duration: 0.093s, episode steps:  28, steps per second: 302, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.536 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33940/100000: episode: 880, duration: 0.073s, episode steps:  25, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 33971/100000: episode: 881, duration: 0.089s, episode steps:  31, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.226 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34000/100000: episode: 882, duration: 0.092s, episode steps:  29, steps per second: 315, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34025/100000: episode: 883, duration: 0.074s, episode steps:  25, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34058/100000: episode: 884, duration: 0.092s, episode steps:  33, steps per second: 361, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34084/100000: episode: 885, duration: 0.092s, episode steps:  26, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.846 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34112/100000: episode: 886, duration: 0.082s, episode steps:  28, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34138/100000: episode: 887, duration: 0.092s, episode steps:  26, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34163/100000: episode: 888, duration: 0.087s, episode steps:  25, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34263/100000: episode: 889, duration: 0.269s, episode steps: 100, steps per second: 371, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34334/100000: episode: 890, duration: 0.195s, episode steps:  71, steps per second: 364, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.408 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34361/100000: episode: 891, duration: 0.090s, episode steps:  27, steps per second: 298, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34435/100000: episode: 892, duration: 0.203s, episode steps:  74, steps per second: 364, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.649 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34460/100000: episode: 893, duration: 0.089s, episode steps:  25, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34533/100000: episode: 894, duration: 0.217s, episode steps:  73, steps per second: 336, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.726 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34560/100000: episode: 895, duration: 0.087s, episode steps:  27, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34588/100000: episode: 896, duration: 0.082s, episode steps:  28, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.357 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34615/100000: episode: 897, duration: 0.088s, episode steps:  27, steps per second: 308, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.778 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34641/100000: episode: 898, duration: 0.081s, episode steps:  26, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34667/100000: episode: 899, duration: 0.077s, episode steps:  26, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34696/100000: episode: 900, duration: 0.100s, episode steps:  29, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.793 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34750/100000: episode: 901, duration: 0.154s, episode steps:  54, steps per second: 350, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.389 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34776/100000: episode: 902, duration: 0.097s, episode steps:  26, steps per second: 267, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34802/100000: episode: 903, duration: 0.092s, episode steps:  26, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34829/100000: episode: 904, duration: 0.084s, episode steps:  27, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34858/100000: episode: 905, duration: 0.096s, episode steps:  29, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.414 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34885/100000: episode: 906, duration: 0.079s, episode steps:  27, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34910/100000: episode: 907, duration: 0.076s, episode steps:  25, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34939/100000: episode: 908, duration: 0.093s, episode steps:  29, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 34964/100000: episode: 909, duration: 0.078s, episode steps:  25, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35089/100000: episode: 910, duration: 0.424s, episode steps: 125, steps per second: 295, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.448 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35115/100000: episode: 911, duration: 0.118s, episode steps:  26, steps per second: 220, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35141/100000: episode: 912, duration: 0.128s, episode steps:  26, steps per second: 203, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35167/100000: episode: 913, duration: 0.117s, episode steps:  26, steps per second: 222, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35196/100000: episode: 914, duration: 0.137s, episode steps:  29, steps per second: 211, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35298/100000: episode: 915, duration: 0.426s, episode steps: 102, steps per second: 240, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.412 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35398/100000: episode: 916, duration: 0.445s, episode steps: 100, steps per second: 225, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.390 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35423/100000: episode: 917, duration: 0.125s, episode steps:  25, steps per second: 199, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35449/100000: episode: 918, duration: 0.137s, episode steps:  26, steps per second: 189, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.846 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35480/100000: episode: 919, duration: 0.147s, episode steps:  31, steps per second: 211, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.710 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35508/100000: episode: 920, duration: 0.149s, episode steps:  28, steps per second: 187, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.714 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35541/100000: episode: 921, duration: 0.139s, episode steps:  33, steps per second: 237, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.455 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35569/100000: episode: 922, duration: 0.140s, episode steps:  28, steps per second: 200, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.821 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35597/100000: episode: 923, duration: 0.124s, episode steps:  28, steps per second: 226, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.679 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35622/100000: episode: 924, duration: 0.117s, episode steps:  25, steps per second: 213, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35695/100000: episode: 925, duration: 0.300s, episode steps:  73, steps per second: 243, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.438 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35766/100000: episode: 926, duration: 0.316s, episode steps:  71, steps per second: 225, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.437 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35840/100000: episode: 927, duration: 0.313s, episode steps:  74, steps per second: 236, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.216 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35911/100000: episode: 928, duration: 0.243s, episode steps:  71, steps per second: 293, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.606 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35937/100000: episode: 929, duration: 0.077s, episode steps:  26, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 35964/100000: episode: 930, duration: 0.083s, episode steps:  27, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36018/100000: episode: 931, duration: 0.162s, episode steps:  54, steps per second: 333, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36047/100000: episode: 932, duration: 0.085s, episode steps:  29, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36076/100000: episode: 933, duration: 0.093s, episode steps:  29, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.310 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36102/100000: episode: 934, duration: 0.092s, episode steps:  26, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36138/100000: episode: 935, duration: 0.109s, episode steps:  36, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.306 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36174/100000: episode: 936, duration: 0.132s, episode steps:  36, steps per second: 273, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.806 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36230/100000: episode: 937, duration: 0.179s, episode steps:  56, steps per second: 312, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.411 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36258/100000: episode: 938, duration: 0.096s, episode steps:  28, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.750 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36284/100000: episode: 939, duration: 0.080s, episode steps:  26, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36405/100000: episode: 940, duration: 0.333s, episode steps: 121, steps per second: 364, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.388 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36438/100000: episode: 941, duration: 0.096s, episode steps:  33, steps per second: 346, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.909 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36511/100000: episode: 942, duration: 0.218s, episode steps:  73, steps per second: 334, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.438 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36536/100000: episode: 943, duration: 0.076s, episode steps:  25, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36561/100000: episode: 944, duration: 0.076s, episode steps:  25, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36594/100000: episode: 945, duration: 0.109s, episode steps:  33, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.424 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36629/100000: episode: 946, duration: 0.102s, episode steps:  35, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36707/100000: episode: 947, duration: 0.226s, episode steps:  78, steps per second: 345, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.692 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36733/100000: episode: 948, duration: 0.081s, episode steps:  26, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36759/100000: episode: 949, duration: 0.074s, episode steps:  26, steps per second: 351, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36787/100000: episode: 950, duration: 0.096s, episode steps:  28, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36861/100000: episode: 951, duration: 0.228s, episode steps:  74, steps per second: 325, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.432 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36916/100000: episode: 952, duration: 0.159s, episode steps:  55, steps per second: 345, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36942/100000: episode: 953, duration: 0.090s, episode steps:  26, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36971/100000: episode: 954, duration: 0.085s, episode steps:  29, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.966 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 36996/100000: episode: 955, duration: 0.077s, episode steps:  25, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.080 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37025/100000: episode: 956, duration: 0.096s, episode steps:  29, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.310 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37056/100000: episode: 957, duration: 0.090s, episode steps:  31, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.387 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37081/100000: episode: 958, duration: 0.077s, episode steps:  25, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37108/100000: episode: 959, duration: 0.088s, episode steps:  27, steps per second: 307, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37133/100000: episode: 960, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37159/100000: episode: 961, duration: 0.078s, episode steps:  26, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37187/100000: episode: 962, duration: 0.107s, episode steps:  28, steps per second: 261, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37217/100000: episode: 963, duration: 0.085s, episode steps:  30, steps per second: 351, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.533 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37244/100000: episode: 964, duration: 0.079s, episode steps:  27, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37270/100000: episode: 965, duration: 0.093s, episode steps:  26, steps per second: 281, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37441/100000: episode: 966, duration: 0.454s, episode steps: 171, steps per second: 377, episode reward:  3.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.596 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37467/100000: episode: 967, duration: 0.077s, episode steps:  26, steps per second: 338, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37497/100000: episode: 968, duration: 0.086s, episode steps:  30, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37530/100000: episode: 969, duration: 0.117s, episode steps:  33, steps per second: 281, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.758 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37557/100000: episode: 970, duration: 0.082s, episode steps:  27, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37582/100000: episode: 971, duration: 0.079s, episode steps:  25, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37635/100000: episode: 972, duration: 0.162s, episode steps:  53, steps per second: 327, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.547 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37660/100000: episode: 973, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37687/100000: episode: 974, duration: 0.093s, episode steps:  27, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.259 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37758/100000: episode: 975, duration: 0.207s, episode steps:  71, steps per second: 343, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37831/100000: episode: 976, duration: 0.193s, episode steps:  73, steps per second: 379, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.575 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37902/100000: episode: 977, duration: 0.213s, episode steps:  71, steps per second: 333, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.451 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37928/100000: episode: 978, duration: 0.078s, episode steps:  26, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37957/100000: episode: 979, duration: 0.084s, episode steps:  29, steps per second: 345, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 37983/100000: episode: 980, duration: 0.090s, episode steps:  26, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38009/100000: episode: 981, duration: 0.075s, episode steps:  26, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.154 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38036/100000: episode: 982, duration: 0.083s, episode steps:  27, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38061/100000: episode: 983, duration: 0.088s, episode steps:  25, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38086/100000: episode: 984, duration: 0.074s, episode steps:  25, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38162/100000: episode: 985, duration: 0.220s, episode steps:  76, steps per second: 345, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.553 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38187/100000: episode: 986, duration: 0.077s, episode steps:  25, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38216/100000: episode: 987, duration: 0.093s, episode steps:  29, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38244/100000: episode: 988, duration: 0.098s, episode steps:  28, steps per second: 285, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.714 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38299/100000: episode: 989, duration: 0.150s, episode steps:  55, steps per second: 367, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38326/100000: episode: 990, duration: 0.088s, episode steps:  27, steps per second: 305, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38404/100000: episode: 991, duration: 0.209s, episode steps:  78, steps per second: 373, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38430/100000: episode: 992, duration: 0.091s, episode steps:  26, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38457/100000: episode: 993, duration: 0.083s, episode steps:  27, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38484/100000: episode: 994, duration: 0.077s, episode steps:  27, steps per second: 351, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38510/100000: episode: 995, duration: 0.090s, episode steps:  26, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.846 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38535/100000: episode: 996, duration: 0.077s, episode steps:  25, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38567/100000: episode: 997, duration: 0.108s, episode steps:  32, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.719 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38596/100000: episode: 998, duration: 0.098s, episode steps:  29, steps per second: 297, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.379 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38626/100000: episode: 999, duration: 0.088s, episode steps:  30, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38714/100000: episode: 1000, duration: 0.243s, episode steps:  88, steps per second: 363, episode reward:  2.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.182 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38814/100000: episode: 1001, duration: 0.275s, episode steps: 100, steps per second: 364, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.620 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38841/100000: episode: 1002, duration: 0.082s, episode steps:  27, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.185 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38877/100000: episode: 1003, duration: 0.105s, episode steps:  36, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.417 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38903/100000: episode: 1004, duration: 0.104s, episode steps:  26, steps per second: 250, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38931/100000: episode: 1005, duration: 0.079s, episode steps:  28, steps per second: 354, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.286 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38956/100000: episode: 1006, duration: 0.076s, episode steps:  25, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 38982/100000: episode: 1007, duration: 0.089s, episode steps:  26, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39007/100000: episode: 1008, duration: 0.077s, episode steps:  25, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39036/100000: episode: 1009, duration: 0.085s, episode steps:  29, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.483 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39061/100000: episode: 1010, duration: 0.088s, episode steps:  25, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39089/100000: episode: 1011, duration: 0.089s, episode steps:  28, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.929 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39115/100000: episode: 1012, duration: 0.080s, episode steps:  26, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39292/100000: episode: 1013, duration: 0.640s, episode steps: 177, steps per second: 277, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.542 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39355/100000: episode: 1014, duration: 0.277s, episode steps:  63, steps per second: 227, episode reward:  1.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.460 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39476/100000: episode: 1015, duration: 0.540s, episode steps: 121, steps per second: 224, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.512 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39529/100000: episode: 1016, duration: 0.239s, episode steps:  53, steps per second: 222, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.585 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39554/100000: episode: 1017, duration: 0.117s, episode steps:  25, steps per second: 214, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39582/100000: episode: 1018, duration: 0.143s, episode steps:  28, steps per second: 195, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39612/100000: episode: 1019, duration: 0.127s, episode steps:  30, steps per second: 236, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.267 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39638/100000: episode: 1020, duration: 0.125s, episode steps:  26, steps per second: 208, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39675/100000: episode: 1021, duration: 0.163s, episode steps:  37, steps per second: 227, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.514 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39701/100000: episode: 1022, duration: 0.145s, episode steps:  26, steps per second: 179, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39726/100000: episode: 1023, duration: 0.111s, episode steps:  25, steps per second: 225, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39751/100000: episode: 1024, duration: 0.116s, episode steps:  25, steps per second: 215, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39777/100000: episode: 1025, duration: 0.120s, episode steps:  26, steps per second: 216, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39812/100000: episode: 1026, duration: 0.166s, episode steps:  35, steps per second: 210, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.629 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39842/100000: episode: 1027, duration: 0.136s, episode steps:  30, steps per second: 221, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39868/100000: episode: 1028, duration: 0.135s, episode steps:  26, steps per second: 192, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39894/100000: episode: 1029, duration: 0.132s, episode steps:  26, steps per second: 197, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.692 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 39995/100000: episode: 1030, duration: 0.432s, episode steps: 101, steps per second: 234, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.356 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40022/100000: episode: 1031, duration: 0.094s, episode steps:  27, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40048/100000: episode: 1032, duration: 0.076s, episode steps:  26, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40073/100000: episode: 1033, duration: 0.088s, episode steps:  25, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40098/100000: episode: 1034, duration: 0.076s, episode steps:  25, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40125/100000: episode: 1035, duration: 0.080s, episode steps:  27, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.259 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40178/100000: episode: 1036, duration: 0.157s, episode steps:  53, steps per second: 337, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.358 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40206/100000: episode: 1037, duration: 0.085s, episode steps:  28, steps per second: 330, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40231/100000: episode: 1038, duration: 0.088s, episode steps:  25, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40261/100000: episode: 1039, duration: 0.107s, episode steps:  30, steps per second: 279, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.567 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40290/100000: episode: 1040, duration: 0.087s, episode steps:  29, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.552 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40325/100000: episode: 1041, duration: 0.116s, episode steps:  35, steps per second: 302, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.800 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40353/100000: episode: 1042, duration: 0.097s, episode steps:  28, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.821 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40378/100000: episode: 1043, duration: 0.076s, episode steps:  25, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40403/100000: episode: 1044, duration: 0.086s, episode steps:  25, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40457/100000: episode: 1045, duration: 0.166s, episode steps:  54, steps per second: 324, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.556 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40482/100000: episode: 1046, duration: 0.085s, episode steps:  25, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40512/100000: episode: 1047, duration: 0.093s, episode steps:  30, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40538/100000: episode: 1048, duration: 0.094s, episode steps:  26, steps per second: 276, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.385 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40572/100000: episode: 1049, duration: 0.117s, episode steps:  34, steps per second: 290, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.647 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40650/100000: episode: 1050, duration: 0.225s, episode steps:  78, steps per second: 347, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.526 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40676/100000: episode: 1051, duration: 0.078s, episode steps:  26, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.308 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40729/100000: episode: 1052, duration: 0.156s, episode steps:  53, steps per second: 339, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.679 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40756/100000: episode: 1053, duration: 0.081s, episode steps:  27, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40782/100000: episode: 1054, duration: 0.079s, episode steps:  26, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40809/100000: episode: 1055, duration: 0.097s, episode steps:  27, steps per second: 279, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.370 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 40912/100000: episode: 1056, duration: 0.295s, episode steps: 103, steps per second: 350, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.534 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41014/100000: episode: 1057, duration: 0.284s, episode steps: 102, steps per second: 359, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.461 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41039/100000: episode: 1058, duration: 0.077s, episode steps:  25, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41064/100000: episode: 1059, duration: 0.075s, episode steps:  25, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41090/100000: episode: 1060, duration: 0.086s, episode steps:  26, steps per second: 302, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 0.846 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41117/100000: episode: 1061, duration: 0.086s, episode steps:  27, steps per second: 316, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41148/100000: episode: 1062, duration: 0.113s, episode steps:  31, steps per second: 275, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.452 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41174/100000: episode: 1063, duration: 0.088s, episode steps:  26, steps per second: 297, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41199/100000: episode: 1064, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41253/100000: episode: 1065, duration: 0.167s, episode steps:  54, steps per second: 323, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.611 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41280/100000: episode: 1066, duration: 0.083s, episode steps:  27, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.037 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41351/100000: episode: 1067, duration: 0.203s, episode steps:  71, steps per second: 349, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41383/100000: episode: 1068, duration: 0.099s, episode steps:  32, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.469 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41411/100000: episode: 1069, duration: 0.090s, episode steps:  28, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.250 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41436/100000: episode: 1070, duration: 0.083s, episode steps:  25, steps per second: 300, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41464/100000: episode: 1071, duration: 0.087s, episode steps:  28, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.107 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41492/100000: episode: 1072, duration: 0.090s, episode steps:  28, steps per second: 312, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.214 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41517/100000: episode: 1073, duration: 0.086s, episode steps:  25, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41548/100000: episode: 1074, duration: 0.091s, episode steps:  31, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.258 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41573/100000: episode: 1075, duration: 0.090s, episode steps:  25, steps per second: 276, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41604/100000: episode: 1076, duration: 0.106s, episode steps:  31, steps per second: 292, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.839 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41629/100000: episode: 1077, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41655/100000: episode: 1078, duration: 0.080s, episode steps:  26, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41680/100000: episode: 1079, duration: 0.088s, episode steps:  25, steps per second: 283, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41705/100000: episode: 1080, duration: 0.073s, episode steps:  25, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41734/100000: episode: 1081, duration: 0.087s, episode steps:  29, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.414 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41762/100000: episode: 1082, duration: 0.097s, episode steps:  28, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41789/100000: episode: 1083, duration: 0.085s, episode steps:  27, steps per second: 320, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41814/100000: episode: 1084, duration: 0.080s, episode steps:  25, steps per second: 311, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 41919/100000: episode: 1085, duration: 0.300s, episode steps: 105, steps per second: 350, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.362 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42027/100000: episode: 1086, duration: 0.306s, episode steps: 108, steps per second: 353, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.639 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42059/100000: episode: 1087, duration: 0.098s, episode steps:  32, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.625 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42132/100000: episode: 1088, duration: 0.214s, episode steps:  73, steps per second: 341, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.562 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42157/100000: episode: 1089, duration: 0.078s, episode steps:  25, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42182/100000: episode: 1090, duration: 0.073s, episode steps:  25, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42207/100000: episode: 1091, duration: 0.083s, episode steps:  25, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42233/100000: episode: 1092, duration: 0.089s, episode steps:  26, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42259/100000: episode: 1093, duration: 0.080s, episode steps:  26, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42286/100000: episode: 1094, duration: 0.089s, episode steps:  27, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.444 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42311/100000: episode: 1095, duration: 0.075s, episode steps:  25, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42342/100000: episode: 1096, duration: 0.093s, episode steps:  31, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.355 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42375/100000: episode: 1097, duration: 0.115s, episode steps:  33, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.455 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42401/100000: episode: 1098, duration: 0.082s, episode steps:  26, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42457/100000: episode: 1099, duration: 0.194s, episode steps:  56, steps per second: 288, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.286 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42482/100000: episode: 1100, duration: 0.077s, episode steps:  25, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42507/100000: episode: 1101, duration: 0.077s, episode steps:  25, steps per second: 324, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42533/100000: episode: 1102, duration: 0.100s, episode steps:  26, steps per second: 259, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42558/100000: episode: 1103, duration: 0.089s, episode steps:  25, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42592/100000: episode: 1104, duration: 0.096s, episode steps:  34, steps per second: 355, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.618 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42617/100000: episode: 1105, duration: 0.095s, episode steps:  25, steps per second: 263, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.640 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42642/100000: episode: 1106, duration: 0.075s, episode steps:  25, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42667/100000: episode: 1107, duration: 0.078s, episode steps:  25, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.160 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42740/100000: episode: 1108, duration: 0.222s, episode steps:  73, steps per second: 329, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.452 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42767/100000: episode: 1109, duration: 0.080s, episode steps:  27, steps per second: 337, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42792/100000: episode: 1110, duration: 0.079s, episode steps:  25, steps per second: 315, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42821/100000: episode: 1111, duration: 0.103s, episode steps:  29, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42848/100000: episode: 1112, duration: 0.084s, episode steps:  27, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.185 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42873/100000: episode: 1113, duration: 0.082s, episode steps:  25, steps per second: 304, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42898/100000: episode: 1114, duration: 0.093s, episode steps:  25, steps per second: 268, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42924/100000: episode: 1115, duration: 0.075s, episode steps:  26, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42950/100000: episode: 1116, duration: 0.078s, episode steps:  26, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 42975/100000: episode: 1117, duration: 0.088s, episode steps:  25, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.880 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43003/100000: episode: 1118, duration: 0.085s, episode steps:  28, steps per second: 331, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43062/100000: episode: 1119, duration: 0.175s, episode steps:  59, steps per second: 337, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.339 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43090/100000: episode: 1120, duration: 0.088s, episode steps:  28, steps per second: 317, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.393 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43121/100000: episode: 1121, duration: 0.091s, episode steps:  31, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.419 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43147/100000: episode: 1122, duration: 0.091s, episode steps:  26, steps per second: 287, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43172/100000: episode: 1123, duration: 0.077s, episode steps:  25, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43229/100000: episode: 1124, duration: 0.276s, episode steps:  57, steps per second: 207, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.561 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43259/100000: episode: 1125, duration: 0.125s, episode steps:  30, steps per second: 240, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.367 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43291/100000: episode: 1126, duration: 0.146s, episode steps:  32, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.906 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43317/100000: episode: 1127, duration: 0.118s, episode steps:  26, steps per second: 220, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.692 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43342/100000: episode: 1128, duration: 0.112s, episode steps:  25, steps per second: 223, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43367/100000: episode: 1129, duration: 0.121s, episode steps:  25, steps per second: 206, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43393/100000: episode: 1130, duration: 0.127s, episode steps:  26, steps per second: 205, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43418/100000: episode: 1131, duration: 0.146s, episode steps:  25, steps per second: 171, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43476/100000: episode: 1132, duration: 0.261s, episode steps:  58, steps per second: 222, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.431 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43505/100000: episode: 1133, duration: 0.132s, episode steps:  29, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43530/100000: episode: 1134, duration: 0.127s, episode steps:  25, steps per second: 196, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43559/100000: episode: 1135, duration: 0.129s, episode steps:  29, steps per second: 224, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.552 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43633/100000: episode: 1136, duration: 0.349s, episode steps:  74, steps per second: 212, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.797 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43659/100000: episode: 1137, duration: 0.128s, episode steps:  26, steps per second: 203, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43684/100000: episode: 1138, duration: 0.133s, episode steps:  25, steps per second: 187, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43711/100000: episode: 1139, duration: 0.120s, episode steps:  27, steps per second: 224, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.963 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43793/100000: episode: 1140, duration: 0.331s, episode steps:  82, steps per second: 248, episode reward:  1.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.354 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43818/100000: episode: 1141, duration: 0.114s, episode steps:  25, steps per second: 219, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43843/100000: episode: 1142, duration: 0.123s, episode steps:  25, steps per second: 204, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43868/100000: episode: 1143, duration: 0.121s, episode steps:  25, steps per second: 206, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43927/100000: episode: 1144, duration: 0.268s, episode steps:  59, steps per second: 220, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.763 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43956/100000: episode: 1145, duration: 0.126s, episode steps:  29, steps per second: 229, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.552 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 43985/100000: episode: 1146, duration: 0.133s, episode steps:  29, steps per second: 218, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.172 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44011/100000: episode: 1147, duration: 0.078s, episode steps:  26, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.038 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44043/100000: episode: 1148, duration: 0.094s, episode steps:  32, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.531 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44071/100000: episode: 1149, duration: 0.090s, episode steps:  28, steps per second: 311, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.429 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44147/100000: episode: 1150, duration: 0.197s, episode steps:  76, steps per second: 385, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.434 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44175/100000: episode: 1151, duration: 0.105s, episode steps:  28, steps per second: 266, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.750 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44204/100000: episode: 1152, duration: 0.083s, episode steps:  29, steps per second: 350, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.276 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44259/100000: episode: 1153, duration: 0.161s, episode steps:  55, steps per second: 341, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.418 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44284/100000: episode: 1154, duration: 0.078s, episode steps:  25, steps per second: 319, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44313/100000: episode: 1155, duration: 0.087s, episode steps:  29, steps per second: 334, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.586 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44339/100000: episode: 1156, duration: 0.087s, episode steps:  26, steps per second: 300, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.231 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44364/100000: episode: 1157, duration: 0.078s, episode steps:  25, steps per second: 321, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.760 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44419/100000: episode: 1158, duration: 0.162s, episode steps:  55, steps per second: 339, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.618 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44484/100000: episode: 1159, duration: 0.172s, episode steps:  65, steps per second: 379, episode reward:  1.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44540/100000: episode: 1160, duration: 0.173s, episode steps:  56, steps per second: 324, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.679 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44570/100000: episode: 1161, duration: 0.087s, episode steps:  30, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.467 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44596/100000: episode: 1162, duration: 0.076s, episode steps:  26, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.654 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44624/100000: episode: 1163, duration: 0.096s, episode steps:  28, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.286 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44654/100000: episode: 1164, duration: 0.100s, episode steps:  30, steps per second: 300, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.433 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44755/100000: episode: 1165, duration: 0.290s, episode steps: 101, steps per second: 348, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.634 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44780/100000: episode: 1166, duration: 0.076s, episode steps:  25, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.960 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44806/100000: episode: 1167, duration: 0.075s, episode steps:  26, steps per second: 345, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.769 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44912/100000: episode: 1168, duration: 0.314s, episode steps: 106, steps per second: 338, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 44937/100000: episode: 1169, duration: 0.074s, episode steps:  25, steps per second: 340, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45043/100000: episode: 1170, duration: 0.294s, episode steps: 106, steps per second: 360, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.528 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45114/100000: episode: 1171, duration: 0.189s, episode steps:  71, steps per second: 375, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.479 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45145/100000: episode: 1172, duration: 0.100s, episode steps:  31, steps per second: 309, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.323 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45170/100000: episode: 1173, duration: 0.072s, episode steps:  25, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.240 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45195/100000: episode: 1174, duration: 0.072s, episode steps:  25, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45227/100000: episode: 1175, duration: 0.124s, episode steps:  32, steps per second: 258, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.344 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45268/100000: episode: 1176, duration: 0.114s, episode steps:  41, steps per second: 360, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.537 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45298/100000: episode: 1177, duration: 0.115s, episode steps:  30, steps per second: 261, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.267 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45330/100000: episode: 1178, duration: 0.111s, episode steps:  32, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45356/100000: episode: 1179, duration: 0.079s, episode steps:  26, steps per second: 329, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45386/100000: episode: 1180, duration: 0.103s, episode steps:  30, steps per second: 291, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45465/100000: episode: 1181, duration: 0.216s, episode steps:  79, steps per second: 366, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45541/100000: episode: 1182, duration: 0.219s, episode steps:  76, steps per second: 347, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.632 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45600/100000: episode: 1183, duration: 0.178s, episode steps:  59, steps per second: 332, episode reward:  1.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.661 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45625/100000: episode: 1184, duration: 0.088s, episode steps:  25, steps per second: 284, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45651/100000: episode: 1185, duration: 0.085s, episode steps:  26, steps per second: 306, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45676/100000: episode: 1186, duration: 0.077s, episode steps:  25, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45702/100000: episode: 1187, duration: 0.084s, episode steps:  26, steps per second: 310, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.846 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45728/100000: episode: 1188, duration: 0.077s, episode steps:  26, steps per second: 339, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45755/100000: episode: 1189, duration: 0.086s, episode steps:  27, steps per second: 316, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.407 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45782/100000: episode: 1190, duration: 0.092s, episode steps:  27, steps per second: 295, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.704 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45808/100000: episode: 1191, duration: 0.079s, episode steps:  26, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45835/100000: episode: 1192, duration: 0.078s, episode steps:  27, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45862/100000: episode: 1193, duration: 0.089s, episode steps:  27, steps per second: 302, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45891/100000: episode: 1194, duration: 0.095s, episode steps:  29, steps per second: 306, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45948/100000: episode: 1195, duration: 0.173s, episode steps:  57, steps per second: 330, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.404 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 45978/100000: episode: 1196, duration: 0.088s, episode steps:  30, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.733 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46007/100000: episode: 1197, duration: 0.087s, episode steps:  29, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.276 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46038/100000: episode: 1198, duration: 0.100s, episode steps:  31, steps per second: 310, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.774 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46063/100000: episode: 1199, duration: 0.078s, episode steps:  25, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.560 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46142/100000: episode: 1200, duration: 0.225s, episode steps:  79, steps per second: 351, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.633 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46167/100000: episode: 1201, duration: 0.072s, episode steps:  25, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46192/100000: episode: 1202, duration: 0.073s, episode steps:  25, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.360 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46217/100000: episode: 1203, duration: 0.083s, episode steps:  25, steps per second: 301, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46242/100000: episode: 1204, duration: 0.090s, episode steps:  25, steps per second: 277, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46274/100000: episode: 1205, duration: 0.092s, episode steps:  32, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.625 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46301/100000: episode: 1206, duration: 0.093s, episode steps:  27, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.000 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46329/100000: episode: 1207, duration: 0.082s, episode steps:  28, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.464 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46358/100000: episode: 1208, duration: 0.085s, episode steps:  29, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.621 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46386/100000: episode: 1209, duration: 0.092s, episode steps:  28, steps per second: 304, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.393 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46462/100000: episode: 1210, duration: 0.201s, episode steps:  76, steps per second: 378, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.434 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46488/100000: episode: 1211, duration: 0.086s, episode steps:  26, steps per second: 303, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.577 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46564/100000: episode: 1212, duration: 0.207s, episode steps:  76, steps per second: 368, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.421 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46589/100000: episode: 1213, duration: 0.119s, episode steps:  25, steps per second: 210, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46621/100000: episode: 1214, duration: 0.102s, episode steps:  32, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46646/100000: episode: 1215, duration: 0.077s, episode steps:  25, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46673/100000: episode: 1216, duration: 0.094s, episode steps:  27, steps per second: 286, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.296 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46699/100000: episode: 1217, duration: 0.078s, episode steps:  26, steps per second: 332, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.038 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46724/100000: episode: 1218, duration: 0.075s, episode steps:  25, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.480 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46797/100000: episode: 1219, duration: 0.221s, episode steps:  73, steps per second: 331, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.521 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46824/100000: episode: 1220, duration: 0.082s, episode steps:  27, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46925/100000: episode: 1221, duration: 0.295s, episode steps: 101, steps per second: 342, episode reward:  2.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.356 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46957/100000: episode: 1222, duration: 0.099s, episode steps:  32, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.312 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 46986/100000: episode: 1223, duration: 0.085s, episode steps:  29, steps per second: 342, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.655 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47012/100000: episode: 1224, duration: 0.091s, episode steps:  26, steps per second: 286, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.808 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47042/100000: episode: 1225, duration: 0.097s, episode steps:  30, steps per second: 310, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.733 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47166/100000: episode: 1226, duration: 0.340s, episode steps: 124, steps per second: 365, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.484 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47196/100000: episode: 1227, duration: 0.091s, episode steps:  30, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.467 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47222/100000: episode: 1228, duration: 0.076s, episode steps:  26, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47255/100000: episode: 1229, duration: 0.119s, episode steps:  33, steps per second: 278, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.576 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47280/100000: episode: 1230, duration: 0.102s, episode steps:  25, steps per second: 245, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47309/100000: episode: 1231, duration: 0.128s, episode steps:  29, steps per second: 226, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.552 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47340/100000: episode: 1232, duration: 0.148s, episode steps:  31, steps per second: 209, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.677 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47365/100000: episode: 1233, duration: 0.135s, episode steps:  25, steps per second: 185, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.280 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47396/100000: episode: 1234, duration: 0.143s, episode steps:  31, steps per second: 218, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.581 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47525/100000: episode: 1235, duration: 0.517s, episode steps: 129, steps per second: 250, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.643 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47552/100000: episode: 1236, duration: 0.114s, episode steps:  27, steps per second: 236, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.519 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47578/100000: episode: 1237, duration: 0.131s, episode steps:  26, steps per second: 198, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.346 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47682/100000: episode: 1238, duration: 0.428s, episode steps: 104, steps per second: 243, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.558 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47713/100000: episode: 1239, duration: 0.135s, episode steps:  31, steps per second: 229, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.677 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47740/100000: episode: 1240, duration: 0.137s, episode steps:  27, steps per second: 198, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47768/100000: episode: 1241, duration: 0.133s, episode steps:  28, steps per second: 211, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.464 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47797/100000: episode: 1242, duration: 0.133s, episode steps:  29, steps per second: 218, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.414 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47831/100000: episode: 1243, duration: 0.142s, episode steps:  34, steps per second: 239, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.618 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47856/100000: episode: 1244, duration: 0.112s, episode steps:  25, steps per second: 223, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.680 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47883/100000: episode: 1245, duration: 0.122s, episode steps:  27, steps per second: 222, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.778 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47910/100000: episode: 1246, duration: 0.138s, episode steps:  27, steps per second: 195, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.630 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47940/100000: episode: 1247, duration: 0.132s, episode steps:  30, steps per second: 227, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.400 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47965/100000: episode: 1248, duration: 0.136s, episode steps:  25, steps per second: 183, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.720 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 47990/100000: episode: 1249, duration: 0.132s, episode steps:  25, steps per second: 189, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.920 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48018/100000: episode: 1250, duration: 0.159s, episode steps:  28, steps per second: 176, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48044/100000: episode: 1251, duration: 0.136s, episode steps:  26, steps per second: 191, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.077 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48072/100000: episode: 1252, duration: 0.128s, episode steps:  28, steps per second: 218, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.429 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48127/100000: episode: 1253, duration: 0.154s, episode steps:  55, steps per second: 357, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.527 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48153/100000: episode: 1254, duration: 0.094s, episode steps:  26, steps per second: 277, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.538 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48178/100000: episode: 1255, duration: 0.097s, episode steps:  25, steps per second: 258, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48281/100000: episode: 1256, duration: 0.300s, episode steps: 103, steps per second: 343, episode reward:  2.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.476 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48311/100000: episode: 1257, duration: 0.092s, episode steps:  30, steps per second: 327, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.567 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48336/100000: episode: 1258, duration: 0.073s, episode steps:  25, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.440 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48415/100000: episode: 1259, duration: 0.219s, episode steps:  79, steps per second: 361, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.392 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48440/100000: episode: 1260, duration: 0.077s, episode steps:  25, steps per second: 323, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48468/100000: episode: 1261, duration: 0.084s, episode steps:  28, steps per second: 333, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.571 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48494/100000: episode: 1262, duration: 0.090s, episode steps:  26, steps per second: 289, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.192 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48519/100000: episode: 1263, duration: 0.078s, episode steps:  25, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48551/100000: episode: 1264, duration: 0.092s, episode steps:  32, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.906 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48625/100000: episode: 1265, duration: 0.217s, episode steps:  74, steps per second: 341, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.216 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48655/100000: episode: 1266, duration: 0.086s, episode steps:  30, steps per second: 349, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.333 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48709/100000: episode: 1267, duration: 0.154s, episode steps:  54, steps per second: 351, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48783/100000: episode: 1268, duration: 0.192s, episode steps:  74, steps per second: 385, episode reward:  1.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.595 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48810/100000: episode: 1269, duration: 0.090s, episode steps:  27, steps per second: 300, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.259 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48843/100000: episode: 1270, duration: 0.095s, episode steps:  33, steps per second: 347, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.576 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48871/100000: episode: 1271, duration: 0.082s, episode steps:  28, steps per second: 343, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.321 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48927/100000: episode: 1272, duration: 0.163s, episode steps:  56, steps per second: 344, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.464 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48952/100000: episode: 1273, duration: 0.085s, episode steps:  25, steps per second: 293, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.840 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 48979/100000: episode: 1274, duration: 0.077s, episode steps:  27, steps per second: 352, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.741 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49009/100000: episode: 1275, duration: 0.102s, episode steps:  30, steps per second: 294, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.667 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49041/100000: episode: 1276, duration: 0.092s, episode steps:  32, steps per second: 348, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.594 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49069/100000: episode: 1277, duration: 0.081s, episode steps:  28, steps per second: 344, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.357 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49097/100000: episode: 1278, duration: 0.097s, episode steps:  28, steps per second: 288, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.286 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49123/100000: episode: 1279, duration: 0.078s, episode steps:  26, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49176/100000: episode: 1280, duration: 0.156s, episode steps:  53, steps per second: 339, episode reward:  1.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.264 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49204/100000: episode: 1281, duration: 0.085s, episode steps:  28, steps per second: 328, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49229/100000: episode: 1282, duration: 0.074s, episode steps:  25, steps per second: 336, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.520 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49259/100000: episode: 1283, duration: 0.097s, episode steps:  30, steps per second: 308, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.500 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49288/100000: episode: 1284, duration: 0.097s, episode steps:  29, steps per second: 298, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.517 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49442/100000: episode: 1285, duration: 0.402s, episode steps: 154, steps per second: 383, episode reward:  3.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.422 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49552/100000: episode: 1286, duration: 0.294s, episode steps: 110, steps per second: 375, episode reward:  2.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.545 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49579/100000: episode: 1287, duration: 0.077s, episode steps:  27, steps per second: 351, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.593 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49620/100000: episode: 1288, duration: 0.110s, episode steps:  41, steps per second: 374, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.098 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49675/100000: episode: 1289, duration: 0.171s, episode steps:  55, steps per second: 321, episode reward:  1.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.636 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49700/100000: episode: 1290, duration: 0.077s, episode steps:  25, steps per second: 325, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.320 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49777/100000: episode: 1291, duration: 0.225s, episode steps:  77, steps per second: 342, episode reward:  1.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.442 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49803/100000: episode: 1292, duration: 0.083s, episode steps:  26, steps per second: 314, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.462 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49828/100000: episode: 1293, duration: 0.073s, episode steps:  25, steps per second: 341, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.200 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49854/100000: episode: 1294, duration: 0.093s, episode steps:  26, steps per second: 279, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.846 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49880/100000: episode: 1295, duration: 0.080s, episode steps:  26, steps per second: 326, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49906/100000: episode: 1296, duration: 0.078s, episode steps:  26, steps per second: 335, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.115 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49932/100000: episode: 1297, duration: 0.093s, episode steps:  26, steps per second: 280, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.731 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49962/100000: episode: 1298, duration: 0.093s, episode steps:  30, steps per second: 322, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.700 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 49989/100000: episode: 1299, duration: 0.096s, episode steps:  27, steps per second: 282, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.481 [0.000, 3.000],  loss: --, mae: --, mean_q: --, mean_eps: --
 50016/100000: episode: 1300, duration: 1.545s, episode steps:  27, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.556 [0.000, 3.000],  loss: 0.023122, mae: 0.303229, mean_q: 0.406631, mean_eps: 0.954993
 50044/100000: episode: 1301, duration: 2.572s, episode steps:  28, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.643 [0.000, 3.000],  loss: 0.009452, mae: 0.305555, mean_q: 0.411279, mean_eps: 0.954973
 50073/100000: episode: 1302, duration: 3.926s, episode steps:  29, steps per second:   7, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.690 [0.000, 3.000],  loss: 0.007241, mae: 0.271411, mean_q: 0.370436, mean_eps: 0.954948
 50099/100000: episode: 1303, duration: 2.371s, episode steps:  26, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.615 [0.000, 3.000],  loss: 0.004771, mae: 0.290234, mean_q: 0.396589, mean_eps: 0.954923
 50125/100000: episode: 1304, duration: 2.417s, episode steps:  26, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.269 [0.000, 3.000],  loss: 0.004450, mae: 0.287748, mean_q: 0.396211, mean_eps: 0.954900
 50152/100000: episode: 1305, duration: 2.451s, episode steps:  27, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.815 [0.000, 3.000],  loss: 0.005075, mae: 0.284013, mean_q: 0.388556, mean_eps: 0.954876
 50178/100000: episode: 1306, duration: 2.376s, episode steps:  26, steps per second:  11, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.423 [0.000, 3.000],  loss: 0.006821, mae: 0.310828, mean_q: 0.425028, mean_eps: 0.954852

